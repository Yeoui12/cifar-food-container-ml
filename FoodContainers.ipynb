{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import datasets,layers, models\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse Class: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "Fine Class for all: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99]\n"
     ]
    }
   ],
   "source": [
    "# ================ DATA PREPARATION STAGE ========================== #\n",
    "# load testing and training data into coarse and fine label respectively\n",
    "(xcoarse_train, ycoarse_train), (xcoarse_test, ycoarse_test) = datasets.cifar100.load_data(label_mode='coarse')\n",
    "print('Coarse Class: {}' .format(np.unique(ycoarse_train)))\n",
    "\n",
    "(xfine_train, yfine_train), (xfine_test, yfine_test) = datasets.cifar100.load_data(label_mode='fine')\n",
    "print('Fine Class for all: {}' .format(np.unique(yfine_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images with 3 coarse label (Food Containers) from TRAINING DATASET: 2500\n"
     ]
    }
   ],
   "source": [
    "# aim for index 3 for coarse, 16-20 for fine for group assignment. (coarse: food containers, fine: bowls,cans,cups, etc..)\n",
    "idx = [i for i in range(len(ycoarse_train)) if ycoarse_train[i] == 3]\n",
    "# checks the coarse label of each sample in the training dataset\n",
    "# append the index of an input image with \"Food containers\" coarse label.    \n",
    "\n",
    "print('Total images with 3 coarse label (Food Containers) from TRAINING DATASET: {}' .format(len(idx)))\n",
    "idx = np.array(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the image training dataset: (2500, 32, 32, 3)\n",
      "Fine Class for the extracted training images: [ 9 10 16 28 61]\n"
     ]
    }
   ],
   "source": [
    "# Extract all image and corresponding \"fine\" label and store in train_images, train_labels variable list.\n",
    "train_images, train_labels = xfine_train[idx], yfine_train[idx]\n",
    "print(\"Shape of the image training dataset: {}\".format(train_images.shape))\n",
    "uniq_fineClass = np.unique(train_labels)\n",
    "print('Fine Class for the extracted training images: {}'.format(uniq_fineClass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images with 3 coarse label (Food Containers) from TESTING DATASET: 500\n"
     ]
    }
   ],
   "source": [
    "idx = [i for i in range(len(ycoarse_test)) if ycoarse_test[i] == 3]\n",
    "# checks the coarse label of each sample in the testing dataset\n",
    "# append the index of an input image with \"Food containers\" coarse label.    \n",
    "\n",
    "print('Total images with 3 coarse label (Food Containers) from TESTING DATASET: {}' .format(len(idx)))\n",
    "idx = np.array(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the image testing dataset: (500, 32, 32, 3)\n",
      "Fine Class for the extracted testing images: [ 9 10 16 28 61]\n"
     ]
    }
   ],
   "source": [
    "# Extract all image and corresponding \"fine\" label and store in test_images, test_labels variable list.\n",
    "test_images, test_labels = xfine_test[idx], yfine_test[idx]\n",
    "print(\"Shape of the image testing dataset: {}\".format(test_images.shape))\n",
    "uniq_fineClass = np.unique(test_labels)\n",
    "print('Fine Class for the extracted testing images: {}'.format(uniq_fineClass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relabel training and testing dataset to start from zero (0).\n",
    "for i in range(len(uniq_fineClass)):\n",
    "  for j in range(len(train_labels)):\n",
    "    if train_labels[j] == uniq_fineClass[i]:\n",
    "      train_labels[j] = i\n",
    "\n",
    "  for j in range(len(test_labels)):\n",
    "    if test_labels[j] == uniq_fineClass[i]:\n",
    "      test_labels[j] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot few samples from images from the TESTING DATASET\n",
    "plt.figure(figsize=(10,2))\n",
    "for i in range(10):\n",
    "  plt.subplot(1,10,i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.grid(False)\n",
    "  plt.imshow(test_images[i], cmap=plt.cm.binary)\n",
    "  plt.xlabel(test_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> \n",
       "\n",
       " max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " batch_normalization              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> \n",
       "\n",
       " max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " batch_normalization_1            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> \n",
       "\n",
       " max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " batch_normalization_2            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> \n",
       "\n",
       " batch_normalization_3            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " conv2d (\u001b[38;5;33mConv2D\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)                \u001b[38;5;34m896\u001b[0m \n",
       "\n",
       " max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " batch_normalization              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)                \u001b[38;5;34m128\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m18,496\u001b[0m \n",
       "\n",
       " max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " batch_normalization_1            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m256\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)                    \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)              \u001b[38;5;34m73,856\u001b[0m \n",
       "\n",
       " max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " batch_normalization_2            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m512\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " dropout_2 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " flatten (\u001b[38;5;33mFlatten\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                   \u001b[38;5;34m131,328\u001b[0m \n",
       "\n",
       " batch_normalization_3            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                     \u001b[38;5;34m1,024\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " dropout_3 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                       \u001b[38;5;34m1,285\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">227,781</span> (889.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m227,781\u001b[0m (889.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">226,821</span> (886.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m226,821\u001b[0m (886.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.2569 - loss: 5.7155 - val_accuracy: 0.3640 - val_loss: 4.6681\n",
      "Epoch 2/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.3464 - loss: 5.0854 - val_accuracy: 0.3600 - val_loss: 4.3776\n",
      "Epoch 3/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3840 - loss: 4.6574 - val_accuracy: 0.4320 - val_loss: 4.0089\n",
      "Epoch 4/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.4096 - loss: 4.3276 - val_accuracy: 0.4520 - val_loss: 3.7926\n",
      "Epoch 5/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4432 - loss: 4.0022 - val_accuracy: 0.4840 - val_loss: 3.5722\n",
      "Epoch 6/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4702 - loss: 3.7764 - val_accuracy: 0.5680 - val_loss: 3.3068\n",
      "Epoch 7/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5007 - loss: 3.4608 - val_accuracy: 0.5880 - val_loss: 3.1258\n",
      "Epoch 8/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.5231 - loss: 3.2734 - val_accuracy: 0.5760 - val_loss: 2.9028\n",
      "Epoch 9/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.5544 - loss: 2.9882 - val_accuracy: 0.5960 - val_loss: 2.7232\n",
      "Epoch 10/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5656 - loss: 2.7971 - val_accuracy: 0.6080 - val_loss: 2.5736\n",
      "Epoch 11/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5928 - loss: 2.6474 - val_accuracy: 0.4920 - val_loss: 2.6481\n",
      "Epoch 1/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5812 - loss: 2.6639\n",
      "Epoch 1: val_accuracy improved from -inf to 0.60800, saving model to C:\\Users\\Zamskie\\Documents\\jason 3rd year\\2ND SEM\\cpe emerging\\bestModel\\best_model2.keras\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5810 - loss: 2.6626 - val_accuracy: 0.6080 - val_loss: 2.4392\n",
      "Epoch 2/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5931 - loss: 2.5057\n",
      "Epoch 2: val_accuracy improved from 0.60800 to 0.61200, saving model to C:\\Users\\Zamskie\\Documents\\jason 3rd year\\2ND SEM\\cpe emerging\\bestModel\\best_model2.keras\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5931 - loss: 2.5041 - val_accuracy: 0.6120 - val_loss: 2.2986\n",
      "Epoch 3/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6039 - loss: 2.3419\n",
      "Epoch 3: val_accuracy did not improve from 0.61200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6039 - loss: 2.3408 - val_accuracy: 0.6040 - val_loss: 2.2077\n",
      "Epoch 4/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6382 - loss: 2.1744\n",
      "Epoch 4: val_accuracy did not improve from 0.61200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6382 - loss: 2.1738 - val_accuracy: 0.5480 - val_loss: 2.2931\n",
      "Epoch 5/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6245 - loss: 2.0455\n",
      "Epoch 5: val_accuracy improved from 0.61200 to 0.65200, saving model to C:\\Users\\Zamskie\\Documents\\jason 3rd year\\2ND SEM\\cpe emerging\\bestModel\\best_model2.keras\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6246 - loss: 2.0450 - val_accuracy: 0.6520 - val_loss: 1.9417\n",
      "Epoch 6/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6481 - loss: 1.9441\n",
      "Epoch 6: val_accuracy improved from 0.65200 to 0.66400, saving model to C:\\Users\\Zamskie\\Documents\\jason 3rd year\\2ND SEM\\cpe emerging\\bestModel\\best_model2.keras\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6482 - loss: 1.9437 - val_accuracy: 0.6640 - val_loss: 1.7815\n",
      "Epoch 7/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6591 - loss: 1.7851\n",
      "Epoch 7: val_accuracy improved from 0.66400 to 0.67600, saving model to C:\\Users\\Zamskie\\Documents\\jason 3rd year\\2ND SEM\\cpe emerging\\bestModel\\best_model2.keras\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6590 - loss: 1.7853 - val_accuracy: 0.6760 - val_loss: 1.7509\n",
      "Epoch 8/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6695 - loss: 1.7076\n",
      "Epoch 8: val_accuracy did not improve from 0.67600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6687 - loss: 1.7085 - val_accuracy: 0.6360 - val_loss: 1.6865\n",
      "Epoch 9/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6931 - loss: 1.6229\n",
      "Epoch 9: val_accuracy did not improve from 0.67600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6925 - loss: 1.6227 - val_accuracy: 0.6560 - val_loss: 1.6177\n",
      "Epoch 10/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6840 - loss: 1.5304\n",
      "Epoch 10: val_accuracy did not improve from 0.67600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6837 - loss: 1.5303 - val_accuracy: 0.6720 - val_loss: 1.5040\n",
      "Epoch 11/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6816 - loss: 1.4992\n",
      "Epoch 11: val_accuracy did not improve from 0.67600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6817 - loss: 1.4982 - val_accuracy: 0.6760 - val_loss: 1.4874\n",
      "Epoch 12/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6893 - loss: 1.4144\n",
      "Epoch 12: val_accuracy did not improve from 0.67600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6890 - loss: 1.4141 - val_accuracy: 0.6440 - val_loss: 1.4238\n",
      "Epoch 13/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7044 - loss: 1.3560\n",
      "Epoch 13: val_accuracy did not improve from 0.67600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7045 - loss: 1.3550 - val_accuracy: 0.6520 - val_loss: 1.3527\n",
      "Epoch 14/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7058 - loss: 1.3159\n",
      "Epoch 14: val_accuracy did not improve from 0.67600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.7054 - loss: 1.3159 - val_accuracy: 0.6600 - val_loss: 1.3351\n",
      "Epoch 15/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7237 - loss: 1.2133\n",
      "Epoch 15: val_accuracy did not improve from 0.67600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7238 - loss: 1.2132 - val_accuracy: 0.6400 - val_loss: 1.4041\n",
      "Epoch 16/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7139 - loss: 1.1725\n",
      "Epoch 16: val_accuracy improved from 0.67600 to 0.68400, saving model to C:\\Users\\Zamskie\\Documents\\jason 3rd year\\2ND SEM\\cpe emerging\\bestModel\\best_model2.keras\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.7137 - loss: 1.1732 - val_accuracy: 0.6840 - val_loss: 1.2718\n",
      "Epoch 17/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7356 - loss: 1.1313\n",
      "Epoch 17: val_accuracy improved from 0.68400 to 0.70000, saving model to C:\\Users\\Zamskie\\Documents\\jason 3rd year\\2ND SEM\\cpe emerging\\bestModel\\best_model2.keras\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.7355 - loss: 1.1314 - val_accuracy: 0.7000 - val_loss: 1.2005\n",
      "Epoch 18/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7542 - loss: 1.0890\n",
      "Epoch 18: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7539 - loss: 1.0897 - val_accuracy: 0.6960 - val_loss: 1.1939\n",
      "Epoch 19/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7338 - loss: 1.0704\n",
      "Epoch 19: val_accuracy did not improve from 0.70000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7337 - loss: 1.0706 - val_accuracy: 0.6720 - val_loss: 1.1959\n",
      "Epoch 20/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7245 - loss: 1.0603\n",
      "Epoch 20: val_accuracy improved from 0.70000 to 0.71600, saving model to C:\\Users\\Zamskie\\Documents\\jason 3rd year\\2ND SEM\\cpe emerging\\bestModel\\best_model2.keras\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.7245 - loss: 1.0602 - val_accuracy: 0.7160 - val_loss: 1.0786\n",
      "Epoch 21/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7313 - loss: 1.0323\n",
      "Epoch 21: val_accuracy did not improve from 0.71600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7314 - loss: 1.0325 - val_accuracy: 0.6440 - val_loss: 1.2647\n",
      "Epoch 22/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7549 - loss: 0.9548\n",
      "Epoch 22: val_accuracy did not improve from 0.71600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7543 - loss: 0.9569 - val_accuracy: 0.6720 - val_loss: 1.1301\n",
      "Epoch 23/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7584 - loss: 0.9736\n",
      "Epoch 23: val_accuracy did not improve from 0.71600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7582 - loss: 0.9736 - val_accuracy: 0.6880 - val_loss: 1.0952\n",
      "Epoch 24/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7479 - loss: 0.9471\n",
      "Epoch 24: val_accuracy did not improve from 0.71600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7477 - loss: 0.9474 - val_accuracy: 0.6600 - val_loss: 1.1909\n",
      "Epoch 25/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7506 - loss: 0.9216\n",
      "Epoch 25: val_accuracy did not improve from 0.71600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7505 - loss: 0.9218 - val_accuracy: 0.6920 - val_loss: 1.0745\n",
      "Epoch 26/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7663 - loss: 0.9013\n",
      "Epoch 26: val_accuracy did not improve from 0.71600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7663 - loss: 0.9013 - val_accuracy: 0.6960 - val_loss: 1.0950\n",
      "Epoch 27/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7691 - loss: 0.8665\n",
      "Epoch 27: val_accuracy did not improve from 0.71600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7685 - loss: 0.8679 - val_accuracy: 0.6680 - val_loss: 1.1188\n",
      "Epoch 28/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7907 - loss: 0.8485\n",
      "Epoch 28: val_accuracy did not improve from 0.71600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7898 - loss: 0.8503 - val_accuracy: 0.6760 - val_loss: 1.0775\n",
      "Epoch 29/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7597 - loss: 0.8785\n",
      "Epoch 29: val_accuracy improved from 0.71600 to 0.72400, saving model to C:\\Users\\Zamskie\\Documents\\jason 3rd year\\2ND SEM\\cpe emerging\\bestModel\\best_model2.keras\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7600 - loss: 0.8780 - val_accuracy: 0.7240 - val_loss: 1.0043\n",
      "Epoch 30/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7668 - loss: 0.8366\n",
      "Epoch 30: val_accuracy did not improve from 0.72400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7662 - loss: 0.8385 - val_accuracy: 0.6880 - val_loss: 1.1213\n",
      "Epoch 31/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7661 - loss: 0.8670\n",
      "Epoch 31: val_accuracy did not improve from 0.72400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7662 - loss: 0.8669 - val_accuracy: 0.6520 - val_loss: 1.2518\n",
      "Epoch 32/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7840 - loss: 0.8009\n",
      "Epoch 32: val_accuracy did not improve from 0.72400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7837 - loss: 0.8017 - val_accuracy: 0.6960 - val_loss: 1.0100\n",
      "Epoch 33/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7737 - loss: 0.8171\n",
      "Epoch 33: val_accuracy did not improve from 0.72400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7731 - loss: 0.8182 - val_accuracy: 0.7080 - val_loss: 1.0320\n",
      "Epoch 34/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7861 - loss: 0.8086\n",
      "Epoch 34: val_accuracy did not improve from 0.72400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7858 - loss: 0.8096 - val_accuracy: 0.6760 - val_loss: 1.1531\n",
      "Epoch 35/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8043 - loss: 0.7723\n",
      "Epoch 35: val_accuracy did not improve from 0.72400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8041 - loss: 0.7731 - val_accuracy: 0.7000 - val_loss: 1.0865\n",
      "Epoch 36/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8093 - loss: 0.7613\n",
      "Epoch 36: val_accuracy did not improve from 0.72400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8083 - loss: 0.7624 - val_accuracy: 0.7000 - val_loss: 1.0366\n",
      "Epoch 37/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8108 - loss: 0.7424\n",
      "Epoch 37: val_accuracy did not improve from 0.72400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8101 - loss: 0.7443 - val_accuracy: 0.6640 - val_loss: 1.1414\n",
      "Epoch 38/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7951 - loss: 0.7557\n",
      "Epoch 38: val_accuracy did not improve from 0.72400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7951 - loss: 0.7560 - val_accuracy: 0.7200 - val_loss: 1.0430\n",
      "Epoch 39/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7841 - loss: 0.7561\n",
      "Epoch 39: val_accuracy did not improve from 0.72400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7842 - loss: 0.7578 - val_accuracy: 0.7000 - val_loss: 1.0615\n",
      "Epoch 40/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8048 - loss: 0.7383\n",
      "Epoch 40: val_accuracy did not improve from 0.72400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8044 - loss: 0.7392 - val_accuracy: 0.6280 - val_loss: 1.2445\n",
      "Epoch 41/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8038 - loss: 0.7432\n",
      "Epoch 41: val_accuracy improved from 0.72400 to 0.72800, saving model to C:\\Users\\Zamskie\\Documents\\jason 3rd year\\2ND SEM\\cpe emerging\\bestModel\\best_model2.keras\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8036 - loss: 0.7441 - val_accuracy: 0.7280 - val_loss: 0.9908\n",
      "Epoch 42/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8145 - loss: 0.7105\n",
      "Epoch 42: val_accuracy improved from 0.72800 to 0.74400, saving model to C:\\Users\\Zamskie\\Documents\\jason 3rd year\\2ND SEM\\cpe emerging\\bestModel\\best_model2.keras\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8144 - loss: 0.7108 - val_accuracy: 0.7440 - val_loss: 0.9920\n",
      "Epoch 43/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8210 - loss: 0.7225\n",
      "Epoch 43: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8208 - loss: 0.7227 - val_accuracy: 0.6720 - val_loss: 1.1065\n",
      "Epoch 44/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8276 - loss: 0.6795\n",
      "Epoch 44: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8275 - loss: 0.6800 - val_accuracy: 0.6960 - val_loss: 0.9988\n",
      "Epoch 45/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8031 - loss: 0.7230\n",
      "Epoch 45: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8029 - loss: 0.7231 - val_accuracy: 0.6480 - val_loss: 1.1446\n",
      "Epoch 46/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8108 - loss: 0.7168\n",
      "Epoch 46: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8105 - loss: 0.7177 - val_accuracy: 0.6960 - val_loss: 1.0193\n",
      "Epoch 47/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8185 - loss: 0.7197\n",
      "Epoch 47: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8186 - loss: 0.7194 - val_accuracy: 0.7360 - val_loss: 0.9687\n",
      "Epoch 48/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8272 - loss: 0.6809\n",
      "Epoch 48: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8269 - loss: 0.6815 - val_accuracy: 0.5720 - val_loss: 1.4283\n",
      "Epoch 49/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8302 - loss: 0.6723\n",
      "Epoch 49: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8300 - loss: 0.6731 - val_accuracy: 0.7280 - val_loss: 1.0507\n",
      "Epoch 50/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8269 - loss: 0.6729\n",
      "Epoch 50: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8268 - loss: 0.6735 - val_accuracy: 0.7360 - val_loss: 1.0122\n",
      "Epoch 51/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8478 - loss: 0.6483\n",
      "Epoch 51: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8470 - loss: 0.6496 - val_accuracy: 0.7080 - val_loss: 1.0441\n",
      "Epoch 52/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8145 - loss: 0.6736\n",
      "Epoch 52: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8144 - loss: 0.6744 - val_accuracy: 0.6240 - val_loss: 1.2550\n",
      "Epoch 53/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8243 - loss: 0.7006\n",
      "Epoch 53: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8241 - loss: 0.7010 - val_accuracy: 0.6920 - val_loss: 1.0989\n",
      "Epoch 54/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8149 - loss: 0.6900\n",
      "Epoch 54: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8150 - loss: 0.6906 - val_accuracy: 0.7240 - val_loss: 1.0211\n",
      "Epoch 55/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8325 - loss: 0.6550\n",
      "Epoch 55: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8324 - loss: 0.6562 - val_accuracy: 0.6640 - val_loss: 1.1849\n",
      "Epoch 56/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8411 - loss: 0.6520\n",
      "Epoch 56: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8410 - loss: 0.6524 - val_accuracy: 0.7200 - val_loss: 1.0404\n",
      "Epoch 57/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8528 - loss: 0.6221\n",
      "Epoch 57: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8522 - loss: 0.6233 - val_accuracy: 0.6960 - val_loss: 1.1631\n",
      "Epoch 58/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8279 - loss: 0.6756\n",
      "Epoch 58: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8277 - loss: 0.6766 - val_accuracy: 0.6880 - val_loss: 1.0946\n",
      "Epoch 59/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8272 - loss: 0.6734\n",
      "Epoch 59: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8272 - loss: 0.6736 - val_accuracy: 0.6960 - val_loss: 1.0737\n",
      "Epoch 60/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8346 - loss: 0.6743\n",
      "Epoch 60: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8348 - loss: 0.6735 - val_accuracy: 0.7000 - val_loss: 1.0919\n",
      "Epoch 61/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8238 - loss: 0.6887\n",
      "Epoch 61: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8239 - loss: 0.6884 - val_accuracy: 0.7080 - val_loss: 1.0541\n",
      "Epoch 62/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8589 - loss: 0.6354\n",
      "Epoch 62: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8584 - loss: 0.6360 - val_accuracy: 0.7040 - val_loss: 1.0869\n",
      "Epoch 63/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8378 - loss: 0.6592\n",
      "Epoch 63: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8375 - loss: 0.6594 - val_accuracy: 0.7080 - val_loss: 1.1137\n",
      "Epoch 64/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8361 - loss: 0.6500\n",
      "Epoch 64: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8362 - loss: 0.6499 - val_accuracy: 0.7080 - val_loss: 1.1404\n",
      "Epoch 65/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8395 - loss: 0.6520\n",
      "Epoch 65: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8395 - loss: 0.6522 - val_accuracy: 0.7000 - val_loss: 1.1397\n",
      "Epoch 66/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8397 - loss: 0.6514\n",
      "Epoch 66: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8398 - loss: 0.6515 - val_accuracy: 0.7280 - val_loss: 1.0830\n",
      "Epoch 67/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8625 - loss: 0.6121\n",
      "Epoch 67: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8621 - loss: 0.6129 - val_accuracy: 0.7120 - val_loss: 1.1455\n",
      "Epoch 68/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8481 - loss: 0.6360\n",
      "Epoch 68: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8480 - loss: 0.6361 - val_accuracy: 0.7200 - val_loss: 1.0865\n",
      "Epoch 69/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8526 - loss: 0.6076\n",
      "Epoch 69: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8522 - loss: 0.6090 - val_accuracy: 0.7160 - val_loss: 1.1225\n",
      "Epoch 70/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8636 - loss: 0.6143\n",
      "Epoch 70: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8631 - loss: 0.6151 - val_accuracy: 0.7160 - val_loss: 1.0657\n",
      "Epoch 71/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8574 - loss: 0.6099\n",
      "Epoch 71: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8573 - loss: 0.6103 - val_accuracy: 0.7000 - val_loss: 1.0760\n",
      "Epoch 72/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8629 - loss: 0.5923\n",
      "Epoch 72: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8626 - loss: 0.5930 - val_accuracy: 0.7120 - val_loss: 1.1116\n",
      "Epoch 73/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8639 - loss: 0.6078\n",
      "Epoch 73: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8637 - loss: 0.6080 - val_accuracy: 0.7040 - val_loss: 1.1403\n",
      "Epoch 74/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8553 - loss: 0.6068\n",
      "Epoch 74: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8552 - loss: 0.6069 - val_accuracy: 0.7000 - val_loss: 1.0985\n",
      "Epoch 75/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8525 - loss: 0.6288\n",
      "Epoch 75: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8523 - loss: 0.6291 - val_accuracy: 0.7080 - val_loss: 1.1328\n",
      "Epoch 76/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8466 - loss: 0.6127\n",
      "Epoch 76: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8470 - loss: 0.6126 - val_accuracy: 0.7280 - val_loss: 1.1032\n",
      "Epoch 77/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8616 - loss: 0.6118\n",
      "Epoch 77: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8617 - loss: 0.6116 - val_accuracy: 0.6880 - val_loss: 1.1922\n",
      "Epoch 78/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8607 - loss: 0.6071\n",
      "Epoch 78: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.8607 - loss: 0.6071 - val_accuracy: 0.6640 - val_loss: 1.2606\n",
      "Epoch 79/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8627 - loss: 0.5972\n",
      "Epoch 79: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8627 - loss: 0.5978 - val_accuracy: 0.7040 - val_loss: 1.0842\n",
      "Epoch 80/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8873 - loss: 0.5532\n",
      "Epoch 80: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8864 - loss: 0.5547 - val_accuracy: 0.6880 - val_loss: 1.1552\n",
      "Epoch 81/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8723 - loss: 0.5720\n",
      "Epoch 81: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8724 - loss: 0.5723 - val_accuracy: 0.7160 - val_loss: 1.0837\n",
      "Epoch 82/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8653 - loss: 0.5882\n",
      "Epoch 82: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8652 - loss: 0.5885 - val_accuracy: 0.6960 - val_loss: 1.1497\n",
      "Epoch 83/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8772 - loss: 0.5661\n",
      "Epoch 83: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8768 - loss: 0.5669 - val_accuracy: 0.7120 - val_loss: 1.1319\n",
      "Epoch 84/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8575 - loss: 0.5663\n",
      "Epoch 84: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.8575 - loss: 0.5670 - val_accuracy: 0.6920 - val_loss: 1.1464\n",
      "Epoch 85/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8762 - loss: 0.5659\n",
      "Epoch 85: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8758 - loss: 0.5669 - val_accuracy: 0.7120 - val_loss: 1.1136\n",
      "Epoch 86/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8634 - loss: 0.5866\n",
      "Epoch 86: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8636 - loss: 0.5866 - val_accuracy: 0.7320 - val_loss: 1.1131\n",
      "Epoch 87/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8481 - loss: 0.6247\n",
      "Epoch 87: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8481 - loss: 0.6247 - val_accuracy: 0.7200 - val_loss: 1.1708\n",
      "Epoch 88/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8886 - loss: 0.5567\n",
      "Epoch 88: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8881 - loss: 0.5577 - val_accuracy: 0.6440 - val_loss: 1.3655\n",
      "Epoch 89/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8711 - loss: 0.5658\n",
      "Epoch 89: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8712 - loss: 0.5660 - val_accuracy: 0.5800 - val_loss: 1.6899\n",
      "Epoch 90/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8622 - loss: 0.6142\n",
      "Epoch 90: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8619 - loss: 0.6149 - val_accuracy: 0.6800 - val_loss: 1.2909\n",
      "Epoch 91/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8761 - loss: 0.5739\n",
      "Epoch 91: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8756 - loss: 0.5755 - val_accuracy: 0.6920 - val_loss: 1.1903\n",
      "Epoch 92/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8766 - loss: 0.5847\n",
      "Epoch 92: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8765 - loss: 0.5850 - val_accuracy: 0.7120 - val_loss: 1.1462\n",
      "Epoch 93/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8585 - loss: 0.6138\n",
      "Epoch 93: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8589 - loss: 0.6130 - val_accuracy: 0.7200 - val_loss: 1.1647\n",
      "Epoch 94/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8694 - loss: 0.5836\n",
      "Epoch 94: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8691 - loss: 0.5843 - val_accuracy: 0.7280 - val_loss: 1.1444\n",
      "Epoch 95/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8817 - loss: 0.5715\n",
      "Epoch 95: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8815 - loss: 0.5719 - val_accuracy: 0.6920 - val_loss: 1.1631\n",
      "Epoch 96/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8779 - loss: 0.5629\n",
      "Epoch 96: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8779 - loss: 0.5629 - val_accuracy: 0.7080 - val_loss: 1.1527\n",
      "Epoch 97/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8866 - loss: 0.5373\n",
      "Epoch 97: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8865 - loss: 0.5379 - val_accuracy: 0.6840 - val_loss: 1.2779\n",
      "Epoch 98/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8788 - loss: 0.5520\n",
      "Epoch 98: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8788 - loss: 0.5519 - val_accuracy: 0.7360 - val_loss: 1.1674\n",
      "Epoch 99/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8881 - loss: 0.5452\n",
      "Epoch 99: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8877 - loss: 0.5457 - val_accuracy: 0.6760 - val_loss: 1.2150\n",
      "Epoch 100/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9076 - loss: 0.5113\n",
      "Epoch 100: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9071 - loss: 0.5124 - val_accuracy: 0.7320 - val_loss: 1.0586\n",
      "Epoch 101/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8826 - loss: 0.5397\n",
      "Epoch 101: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8826 - loss: 0.5397 - val_accuracy: 0.7320 - val_loss: 1.0853\n",
      "Epoch 102/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8894 - loss: 0.5362\n",
      "Epoch 102: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8893 - loss: 0.5365 - val_accuracy: 0.6960 - val_loss: 1.2578\n",
      "Epoch 103/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8904 - loss: 0.5343\n",
      "Epoch 103: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8901 - loss: 0.5354 - val_accuracy: 0.7240 - val_loss: 1.1829\n",
      "Epoch 104/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8862 - loss: 0.5400\n",
      "Epoch 104: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8859 - loss: 0.5408 - val_accuracy: 0.7040 - val_loss: 1.1476\n",
      "Epoch 105/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8709 - loss: 0.5732\n",
      "Epoch 105: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8711 - loss: 0.5733 - val_accuracy: 0.7200 - val_loss: 1.0990\n",
      "Epoch 106/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8948 - loss: 0.5293\n",
      "Epoch 106: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8948 - loss: 0.5297 - val_accuracy: 0.7240 - val_loss: 1.1025\n",
      "Epoch 107/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8831 - loss: 0.5505\n",
      "Epoch 107: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8833 - loss: 0.5501 - val_accuracy: 0.7120 - val_loss: 1.1612\n",
      "Epoch 108/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8767 - loss: 0.5500\n",
      "Epoch 108: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8767 - loss: 0.5504 - val_accuracy: 0.7160 - val_loss: 1.1741\n",
      "Epoch 109/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8860 - loss: 0.5460\n",
      "Epoch 109: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8862 - loss: 0.5457 - val_accuracy: 0.7120 - val_loss: 1.1366\n",
      "Epoch 110/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8960 - loss: 0.5395\n",
      "Epoch 110: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8956 - loss: 0.5397 - val_accuracy: 0.7240 - val_loss: 1.1669\n",
      "Epoch 111/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8997 - loss: 0.5354\n",
      "Epoch 111: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8992 - loss: 0.5359 - val_accuracy: 0.7040 - val_loss: 1.1455\n",
      "Epoch 112/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8915 - loss: 0.5245\n",
      "Epoch 112: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8911 - loss: 0.5255 - val_accuracy: 0.7240 - val_loss: 1.2303\n",
      "Epoch 113/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9039 - loss: 0.4875\n",
      "Epoch 113: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9035 - loss: 0.4889 - val_accuracy: 0.7080 - val_loss: 1.2335\n",
      "Epoch 114/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8960 - loss: 0.5218\n",
      "Epoch 114: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8959 - loss: 0.5220 - val_accuracy: 0.7320 - val_loss: 1.0996\n",
      "Epoch 115/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9004 - loss: 0.5093\n",
      "Epoch 115: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9003 - loss: 0.5095 - val_accuracy: 0.7160 - val_loss: 1.2292\n",
      "Epoch 116/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8994 - loss: 0.5008\n",
      "Epoch 116: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8991 - loss: 0.5022 - val_accuracy: 0.7080 - val_loss: 1.2743\n",
      "Epoch 117/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8958 - loss: 0.5281\n",
      "Epoch 117: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8952 - loss: 0.5298 - val_accuracy: 0.6840 - val_loss: 1.3315\n",
      "Epoch 118/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8849 - loss: 0.5726\n",
      "Epoch 118: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8847 - loss: 0.5728 - val_accuracy: 0.7320 - val_loss: 1.1261\n",
      "Epoch 119/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8744 - loss: 0.5783\n",
      "Epoch 119: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8746 - loss: 0.5776 - val_accuracy: 0.7240 - val_loss: 1.2148\n",
      "Epoch 120/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9057 - loss: 0.5366\n",
      "Epoch 120: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9053 - loss: 0.5373 - val_accuracy: 0.7120 - val_loss: 1.1675\n",
      "Epoch 121/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8991 - loss: 0.5351\n",
      "Epoch 121: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8986 - loss: 0.5357 - val_accuracy: 0.6720 - val_loss: 1.3847\n",
      "Epoch 122/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9018 - loss: 0.5288\n",
      "Epoch 122: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9016 - loss: 0.5288 - val_accuracy: 0.7280 - val_loss: 1.1879\n",
      "Epoch 123/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8957 - loss: 0.5264\n",
      "Epoch 123: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8956 - loss: 0.5265 - val_accuracy: 0.7360 - val_loss: 1.1960\n",
      "Epoch 124/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8860 - loss: 0.5426\n",
      "Epoch 124: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8860 - loss: 0.5425 - val_accuracy: 0.7160 - val_loss: 1.1813\n",
      "Epoch 125/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8892 - loss: 0.5565\n",
      "Epoch 125: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8892 - loss: 0.5563 - val_accuracy: 0.7200 - val_loss: 1.2683\n",
      "Epoch 126/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9096 - loss: 0.5093\n",
      "Epoch 126: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9094 - loss: 0.5096 - val_accuracy: 0.6720 - val_loss: 1.3267\n",
      "Epoch 127/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8742 - loss: 0.5575\n",
      "Epoch 127: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8744 - loss: 0.5573 - val_accuracy: 0.7280 - val_loss: 1.2596\n",
      "Epoch 128/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9004 - loss: 0.5065\n",
      "Epoch 128: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9002 - loss: 0.5074 - val_accuracy: 0.6880 - val_loss: 1.2693\n",
      "Epoch 129/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9070 - loss: 0.5041\n",
      "Epoch 129: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9069 - loss: 0.5042 - val_accuracy: 0.7280 - val_loss: 1.1481\n",
      "Epoch 130/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8945 - loss: 0.5180\n",
      "Epoch 130: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8947 - loss: 0.5187 - val_accuracy: 0.7080 - val_loss: 1.2370\n",
      "Epoch 131/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8994 - loss: 0.5333\n",
      "Epoch 131: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8992 - loss: 0.5335 - val_accuracy: 0.7400 - val_loss: 1.1166\n",
      "Epoch 132/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9016 - loss: 0.5152\n",
      "Epoch 132: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9016 - loss: 0.5158 - val_accuracy: 0.7200 - val_loss: 1.1927\n",
      "Epoch 133/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8940 - loss: 0.5207\n",
      "Epoch 133: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8939 - loss: 0.5210 - val_accuracy: 0.7000 - val_loss: 1.2863\n",
      "Epoch 134/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9002 - loss: 0.5356\n",
      "Epoch 134: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9002 - loss: 0.5356 - val_accuracy: 0.6960 - val_loss: 1.2089\n",
      "Epoch 135/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8927 - loss: 0.5119\n",
      "Epoch 135: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8927 - loss: 0.5124 - val_accuracy: 0.7040 - val_loss: 1.3004\n",
      "Epoch 136/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9159 - loss: 0.4794\n",
      "Epoch 136: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9158 - loss: 0.4798 - val_accuracy: 0.7360 - val_loss: 1.1791\n",
      "Epoch 137/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9094 - loss: 0.4966\n",
      "Epoch 137: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9093 - loss: 0.4966 - val_accuracy: 0.7360 - val_loss: 1.1855\n",
      "Epoch 138/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9055 - loss: 0.5201\n",
      "Epoch 138: val_accuracy did not improve from 0.74400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9054 - loss: 0.5201 - val_accuracy: 0.7160 - val_loss: 1.1320\n",
      "Epoch 139/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8955 - loss: 0.5127\n",
      "Epoch 139: val_accuracy improved from 0.74400 to 0.74800, saving model to C:\\Users\\Zamskie\\Documents\\jason 3rd year\\2ND SEM\\cpe emerging\\bestModel\\best_model2.keras\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8959 - loss: 0.5125 - val_accuracy: 0.7480 - val_loss: 1.1918\n",
      "Epoch 140/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9037 - loss: 0.4912\n",
      "Epoch 140: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9040 - loss: 0.4907 - val_accuracy: 0.7480 - val_loss: 1.1153\n",
      "Epoch 141/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9004 - loss: 0.5036\n",
      "Epoch 141: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9001 - loss: 0.5043 - val_accuracy: 0.7320 - val_loss: 1.1354\n",
      "Epoch 142/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9038 - loss: 0.4848\n",
      "Epoch 142: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9040 - loss: 0.4850 - val_accuracy: 0.7080 - val_loss: 1.2039\n",
      "Epoch 143/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9134 - loss: 0.4824\n",
      "Epoch 143: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9129 - loss: 0.4832 - val_accuracy: 0.7400 - val_loss: 1.2455\n",
      "Epoch 144/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8971 - loss: 0.5351\n",
      "Epoch 144: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8969 - loss: 0.5353 - val_accuracy: 0.7320 - val_loss: 1.1764\n",
      "Epoch 145/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8938 - loss: 0.5268\n",
      "Epoch 145: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8940 - loss: 0.5262 - val_accuracy: 0.7080 - val_loss: 1.2699\n",
      "Epoch 146/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9087 - loss: 0.5103\n",
      "Epoch 146: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9087 - loss: 0.5104 - val_accuracy: 0.7480 - val_loss: 1.2085\n",
      "Epoch 147/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9101 - loss: 0.4901\n",
      "Epoch 147: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9103 - loss: 0.4903 - val_accuracy: 0.7400 - val_loss: 1.1842\n",
      "Epoch 148/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9149 - loss: 0.4876\n",
      "Epoch 148: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9146 - loss: 0.4881 - val_accuracy: 0.6880 - val_loss: 1.3931\n",
      "Epoch 149/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8884 - loss: 0.5140\n",
      "Epoch 149: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8887 - loss: 0.5143 - val_accuracy: 0.7120 - val_loss: 1.2173\n",
      "Epoch 150/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9004 - loss: 0.5145\n",
      "Epoch 150: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9001 - loss: 0.5148 - val_accuracy: 0.7160 - val_loss: 1.1445\n",
      "Epoch 151/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8998 - loss: 0.5126\n",
      "Epoch 151: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8999 - loss: 0.5130 - val_accuracy: 0.6760 - val_loss: 1.4442\n",
      "Epoch 152/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9134 - loss: 0.4625\n",
      "Epoch 152: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9132 - loss: 0.4636 - val_accuracy: 0.7320 - val_loss: 1.1155\n",
      "Epoch 153/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9083 - loss: 0.4981\n",
      "Epoch 153: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9085 - loss: 0.4978 - val_accuracy: 0.7040 - val_loss: 1.1899\n",
      "Epoch 154/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9084 - loss: 0.4981\n",
      "Epoch 154: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9079 - loss: 0.4987 - val_accuracy: 0.7080 - val_loss: 1.2284\n",
      "Epoch 155/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9158 - loss: 0.4914\n",
      "Epoch 155: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9157 - loss: 0.4918 - val_accuracy: 0.7040 - val_loss: 1.1903\n",
      "Epoch 156/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8915 - loss: 0.5216\n",
      "Epoch 156: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8915 - loss: 0.5215 - val_accuracy: 0.7040 - val_loss: 1.2634\n",
      "Epoch 157/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8923 - loss: 0.5141\n",
      "Epoch 157: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8926 - loss: 0.5143 - val_accuracy: 0.7400 - val_loss: 1.1635\n",
      "Epoch 158/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8993 - loss: 0.5150\n",
      "Epoch 158: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8995 - loss: 0.5146 - val_accuracy: 0.6840 - val_loss: 1.2480\n",
      "Epoch 159/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9112 - loss: 0.4740\n",
      "Epoch 159: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9109 - loss: 0.4752 - val_accuracy: 0.7200 - val_loss: 1.1671\n",
      "Epoch 160/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9251 - loss: 0.4508\n",
      "Epoch 160: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9246 - loss: 0.4521 - val_accuracy: 0.7040 - val_loss: 1.2710\n",
      "Epoch 161/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9220 - loss: 0.4531\n",
      "Epoch 161: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9217 - loss: 0.4543 - val_accuracy: 0.7320 - val_loss: 1.2000\n",
      "Epoch 162/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9059 - loss: 0.4901\n",
      "Epoch 162: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9056 - loss: 0.4909 - val_accuracy: 0.7240 - val_loss: 1.2290\n",
      "Epoch 163/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8967 - loss: 0.5045\n",
      "Epoch 163: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8970 - loss: 0.5041 - val_accuracy: 0.7400 - val_loss: 1.2008\n",
      "Epoch 164/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9283 - loss: 0.4607\n",
      "Epoch 164: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9277 - loss: 0.4620 - val_accuracy: 0.7320 - val_loss: 1.1747\n",
      "Epoch 165/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9019 - loss: 0.5032\n",
      "Epoch 165: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9018 - loss: 0.5034 - val_accuracy: 0.7080 - val_loss: 1.3095\n",
      "Epoch 166/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9071 - loss: 0.4867\n",
      "Epoch 166: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9070 - loss: 0.4873 - val_accuracy: 0.7400 - val_loss: 1.2192\n",
      "Epoch 167/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9124 - loss: 0.4750\n",
      "Epoch 167: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9123 - loss: 0.4755 - val_accuracy: 0.7120 - val_loss: 1.2579\n",
      "Epoch 168/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9175 - loss: 0.4652\n",
      "Epoch 168: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9174 - loss: 0.4655 - val_accuracy: 0.6880 - val_loss: 1.3999\n",
      "Epoch 169/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9024 - loss: 0.4937\n",
      "Epoch 169: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9025 - loss: 0.4939 - val_accuracy: 0.7360 - val_loss: 1.2062\n",
      "Epoch 170/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8993 - loss: 0.4965\n",
      "Epoch 170: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8990 - loss: 0.4977 - val_accuracy: 0.7160 - val_loss: 1.2490\n",
      "Epoch 171/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8983 - loss: 0.5162\n",
      "Epoch 171: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8987 - loss: 0.5156 - val_accuracy: 0.7040 - val_loss: 1.3156\n",
      "Epoch 172/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9191 - loss: 0.4763\n",
      "Epoch 172: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9189 - loss: 0.4763 - val_accuracy: 0.7280 - val_loss: 1.2658\n",
      "Epoch 173/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9090 - loss: 0.4818\n",
      "Epoch 173: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9090 - loss: 0.4820 - val_accuracy: 0.7160 - val_loss: 1.3223\n",
      "Epoch 174/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9084 - loss: 0.5064\n",
      "Epoch 174: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9083 - loss: 0.5067 - val_accuracy: 0.7000 - val_loss: 1.3148\n",
      "Epoch 175/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9206 - loss: 0.4404\n",
      "Epoch 175: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9205 - loss: 0.4410 - val_accuracy: 0.7400 - val_loss: 1.2290\n",
      "Epoch 176/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9060 - loss: 0.4805\n",
      "Epoch 176: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9063 - loss: 0.4798 - val_accuracy: 0.7280 - val_loss: 1.2221\n",
      "Epoch 177/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9252 - loss: 0.4542\n",
      "Epoch 177: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9246 - loss: 0.4550 - val_accuracy: 0.7240 - val_loss: 1.2275\n",
      "Epoch 178/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9133 - loss: 0.4569\n",
      "Epoch 178: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9132 - loss: 0.4576 - val_accuracy: 0.7120 - val_loss: 1.1884\n",
      "Epoch 179/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9236 - loss: 0.4571\n",
      "Epoch 179: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9234 - loss: 0.4574 - val_accuracy: 0.7160 - val_loss: 1.2839\n",
      "Epoch 180/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9194 - loss: 0.4483\n",
      "Epoch 180: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9196 - loss: 0.4481 - val_accuracy: 0.7160 - val_loss: 1.2319\n",
      "Epoch 181/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9194 - loss: 0.4651\n",
      "Epoch 181: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9190 - loss: 0.4662 - val_accuracy: 0.7160 - val_loss: 1.2366\n",
      "Epoch 182/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9082 - loss: 0.4835\n",
      "Epoch 182: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9083 - loss: 0.4835 - val_accuracy: 0.7040 - val_loss: 1.2757\n",
      "Epoch 183/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9147 - loss: 0.4734\n",
      "Epoch 183: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9147 - loss: 0.4735 - val_accuracy: 0.6640 - val_loss: 1.3836\n",
      "Epoch 184/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9114 - loss: 0.4949\n",
      "Epoch 184: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9115 - loss: 0.4946 - val_accuracy: 0.7160 - val_loss: 1.2749\n",
      "Epoch 185/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9183 - loss: 0.4699\n",
      "Epoch 185: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9183 - loss: 0.4702 - val_accuracy: 0.7240 - val_loss: 1.2730\n",
      "Epoch 186/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9072 - loss: 0.5072\n",
      "Epoch 186: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.9072 - loss: 0.5071 - val_accuracy: 0.6880 - val_loss: 1.3269\n",
      "Epoch 187/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9215 - loss: 0.4757\n",
      "Epoch 187: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9212 - loss: 0.4761 - val_accuracy: 0.7240 - val_loss: 1.2775\n",
      "Epoch 188/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9171 - loss: 0.4727\n",
      "Epoch 188: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9170 - loss: 0.4728 - val_accuracy: 0.7040 - val_loss: 1.3950\n",
      "Epoch 189/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9062 - loss: 0.4939\n",
      "Epoch 189: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9061 - loss: 0.4939 - val_accuracy: 0.7200 - val_loss: 1.4396\n",
      "Epoch 190/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9143 - loss: 0.4815\n",
      "Epoch 190: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9144 - loss: 0.4813 - val_accuracy: 0.7200 - val_loss: 1.2571\n",
      "Epoch 191/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9220 - loss: 0.4560\n",
      "Epoch 191: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9219 - loss: 0.4563 - val_accuracy: 0.7000 - val_loss: 1.2875\n",
      "Epoch 192/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9090 - loss: 0.4723\n",
      "Epoch 192: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9089 - loss: 0.4725 - val_accuracy: 0.7360 - val_loss: 1.2660\n",
      "Epoch 193/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9329 - loss: 0.4475\n",
      "Epoch 193: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9324 - loss: 0.4487 - val_accuracy: 0.7400 - val_loss: 1.3352\n",
      "Epoch 194/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9220 - loss: 0.4737\n",
      "Epoch 194: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9220 - loss: 0.4740 - val_accuracy: 0.6880 - val_loss: 1.4756\n",
      "Epoch 195/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9086 - loss: 0.4936\n",
      "Epoch 195: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9091 - loss: 0.4927 - val_accuracy: 0.7360 - val_loss: 1.2970\n",
      "Epoch 196/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9351 - loss: 0.4439\n",
      "Epoch 196: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9346 - loss: 0.4448 - val_accuracy: 0.7440 - val_loss: 1.3626\n",
      "Epoch 197/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9088 - loss: 0.4772\n",
      "Epoch 197: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9088 - loss: 0.4773 - val_accuracy: 0.7160 - val_loss: 1.3898\n",
      "Epoch 198/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9209 - loss: 0.4638\n",
      "Epoch 198: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9210 - loss: 0.4637 - val_accuracy: 0.7280 - val_loss: 1.3374\n",
      "Epoch 199/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9152 - loss: 0.4666\n",
      "Epoch 199: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9149 - loss: 0.4677 - val_accuracy: 0.6800 - val_loss: 1.3753\n",
      "Epoch 200/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9217 - loss: 0.4721\n",
      "Epoch 200: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9217 - loss: 0.4720 - val_accuracy: 0.7200 - val_loss: 1.2982\n",
      "Epoch 201/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9117 - loss: 0.4816\n",
      "Epoch 201: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9118 - loss: 0.4815 - val_accuracy: 0.7240 - val_loss: 1.2575\n",
      "Epoch 202/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9338 - loss: 0.4300\n",
      "Epoch 202: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9336 - loss: 0.4304 - val_accuracy: 0.7440 - val_loss: 1.2218\n",
      "Epoch 203/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9135 - loss: 0.4615\n",
      "Epoch 203: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9134 - loss: 0.4618 - val_accuracy: 0.7240 - val_loss: 1.3235\n",
      "Epoch 204/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9262 - loss: 0.4540\n",
      "Epoch 204: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9261 - loss: 0.4546 - val_accuracy: 0.7360 - val_loss: 1.2260\n",
      "Epoch 205/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9170 - loss: 0.4682\n",
      "Epoch 205: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9169 - loss: 0.4688 - val_accuracy: 0.7120 - val_loss: 1.2745\n",
      "Epoch 206/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9103 - loss: 0.4974\n",
      "Epoch 206: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9103 - loss: 0.4973 - val_accuracy: 0.7360 - val_loss: 1.2776\n",
      "Epoch 207/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9142 - loss: 0.4736\n",
      "Epoch 207: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9140 - loss: 0.4737 - val_accuracy: 0.7320 - val_loss: 1.2442\n",
      "Epoch 208/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9227 - loss: 0.4529\n",
      "Epoch 208: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9225 - loss: 0.4535 - val_accuracy: 0.7160 - val_loss: 1.2578\n",
      "Epoch 209/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9140 - loss: 0.4509\n",
      "Epoch 209: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9139 - loss: 0.4512 - val_accuracy: 0.7280 - val_loss: 1.2164\n",
      "Epoch 210/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9149 - loss: 0.4894\n",
      "Epoch 210: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9149 - loss: 0.4893 - val_accuracy: 0.7160 - val_loss: 1.2549\n",
      "Epoch 211/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9304 - loss: 0.4211\n",
      "Epoch 211: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9303 - loss: 0.4214 - val_accuracy: 0.7160 - val_loss: 1.2521\n",
      "Epoch 212/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9269 - loss: 0.4377\n",
      "Epoch 212: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9267 - loss: 0.4387 - val_accuracy: 0.7280 - val_loss: 1.3503\n",
      "Epoch 213/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9180 - loss: 0.4435\n",
      "Epoch 213: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9180 - loss: 0.4439 - val_accuracy: 0.6920 - val_loss: 1.3983\n",
      "Epoch 214/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9242 - loss: 0.4585\n",
      "Epoch 214: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9241 - loss: 0.4583 - val_accuracy: 0.7000 - val_loss: 1.2599\n",
      "Epoch 215/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9199 - loss: 0.4524\n",
      "Epoch 215: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9199 - loss: 0.4523 - val_accuracy: 0.7200 - val_loss: 1.3690\n",
      "Epoch 216/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9187 - loss: 0.4879\n",
      "Epoch 216: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9186 - loss: 0.4876 - val_accuracy: 0.7160 - val_loss: 1.2946\n",
      "Epoch 217/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9022 - loss: 0.4736\n",
      "Epoch 217: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9028 - loss: 0.4730 - val_accuracy: 0.7240 - val_loss: 1.2731\n",
      "Epoch 218/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9402 - loss: 0.4092\n",
      "Epoch 218: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9401 - loss: 0.4095 - val_accuracy: 0.7360 - val_loss: 1.3593\n",
      "Epoch 219/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9288 - loss: 0.4257\n",
      "Epoch 219: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9287 - loss: 0.4266 - val_accuracy: 0.7240 - val_loss: 1.4469\n",
      "Epoch 220/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9036 - loss: 0.4712\n",
      "Epoch 220: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9041 - loss: 0.4709 - val_accuracy: 0.6800 - val_loss: 1.4952\n",
      "Epoch 221/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9135 - loss: 0.4539\n",
      "Epoch 221: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9135 - loss: 0.4540 - val_accuracy: 0.7120 - val_loss: 1.3485\n",
      "Epoch 222/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9207 - loss: 0.4489\n",
      "Epoch 222: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9205 - loss: 0.4495 - val_accuracy: 0.7000 - val_loss: 1.3779\n",
      "Epoch 223/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9295 - loss: 0.4426\n",
      "Epoch 223: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9291 - loss: 0.4434 - val_accuracy: 0.7080 - val_loss: 1.3712\n",
      "Epoch 224/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9181 - loss: 0.4668\n",
      "Epoch 224: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9181 - loss: 0.4665 - val_accuracy: 0.7120 - val_loss: 1.3740\n",
      "Epoch 225/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9348 - loss: 0.4253\n",
      "Epoch 225: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9343 - loss: 0.4266 - val_accuracy: 0.6040 - val_loss: 1.5938\n",
      "Epoch 226/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9276 - loss: 0.4379\n",
      "Epoch 226: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9276 - loss: 0.4379 - val_accuracy: 0.7240 - val_loss: 1.3464\n",
      "Epoch 227/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9301 - loss: 0.4307\n",
      "Epoch 227: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9300 - loss: 0.4308 - val_accuracy: 0.6880 - val_loss: 1.4002\n",
      "Epoch 228/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9300 - loss: 0.4319\n",
      "Epoch 228: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9295 - loss: 0.4325 - val_accuracy: 0.7200 - val_loss: 1.3131\n",
      "Epoch 229/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9294 - loss: 0.4574\n",
      "Epoch 229: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9291 - loss: 0.4572 - val_accuracy: 0.6080 - val_loss: 1.9110\n",
      "Epoch 230/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9364 - loss: 0.4143\n",
      "Epoch 230: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9363 - loss: 0.4146 - val_accuracy: 0.7280 - val_loss: 1.2777\n",
      "Epoch 231/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9283 - loss: 0.4205\n",
      "Epoch 231: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9283 - loss: 0.4212 - val_accuracy: 0.7240 - val_loss: 1.2706\n",
      "Epoch 232/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9316 - loss: 0.4194\n",
      "Epoch 232: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9312 - loss: 0.4205 - val_accuracy: 0.7200 - val_loss: 1.2578\n",
      "Epoch 233/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9252 - loss: 0.4483\n",
      "Epoch 233: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9252 - loss: 0.4484 - val_accuracy: 0.7040 - val_loss: 1.4507\n",
      "Epoch 234/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9247 - loss: 0.4274\n",
      "Epoch 234: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9246 - loss: 0.4280 - val_accuracy: 0.6960 - val_loss: 1.4381\n",
      "Epoch 235/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9192 - loss: 0.4390\n",
      "Epoch 235: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9192 - loss: 0.4391 - val_accuracy: 0.7200 - val_loss: 1.2886\n",
      "Epoch 236/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9372 - loss: 0.4137\n",
      "Epoch 236: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9369 - loss: 0.4145 - val_accuracy: 0.7000 - val_loss: 1.3462\n",
      "Epoch 237/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9354 - loss: 0.4155\n",
      "Epoch 237: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9350 - loss: 0.4162 - val_accuracy: 0.7240 - val_loss: 1.2816\n",
      "Epoch 238/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9337 - loss: 0.4222\n",
      "Epoch 238: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9335 - loss: 0.4228 - val_accuracy: 0.6880 - val_loss: 1.3829\n",
      "Epoch 239/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9230 - loss: 0.4507\n",
      "Epoch 239: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9228 - loss: 0.4511 - val_accuracy: 0.7400 - val_loss: 1.3102\n",
      "Epoch 240/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9338 - loss: 0.4162\n",
      "Epoch 240: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9337 - loss: 0.4164 - val_accuracy: 0.7080 - val_loss: 1.2660\n",
      "Epoch 241/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9312 - loss: 0.4367\n",
      "Epoch 241: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9312 - loss: 0.4369 - val_accuracy: 0.7400 - val_loss: 1.1693\n",
      "Epoch 242/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9367 - loss: 0.4102\n",
      "Epoch 242: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9365 - loss: 0.4103 - val_accuracy: 0.7240 - val_loss: 1.1604\n",
      "Epoch 243/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9343 - loss: 0.4314\n",
      "Epoch 243: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9342 - loss: 0.4317 - val_accuracy: 0.6880 - val_loss: 1.3714\n",
      "Epoch 244/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9356 - loss: 0.4142\n",
      "Epoch 244: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9355 - loss: 0.4145 - val_accuracy: 0.7320 - val_loss: 1.2985\n",
      "Epoch 245/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9334 - loss: 0.4338\n",
      "Epoch 245: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9329 - loss: 0.4345 - val_accuracy: 0.7160 - val_loss: 1.3442\n",
      "Epoch 246/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9212 - loss: 0.4438\n",
      "Epoch 246: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9213 - loss: 0.4441 - val_accuracy: 0.6880 - val_loss: 1.3759\n",
      "Epoch 247/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9260 - loss: 0.4296\n",
      "Epoch 247: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9259 - loss: 0.4299 - val_accuracy: 0.7160 - val_loss: 1.2702\n",
      "Epoch 248/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9242 - loss: 0.4367\n",
      "Epoch 248: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9244 - loss: 0.4365 - val_accuracy: 0.7160 - val_loss: 1.2873\n",
      "Epoch 249/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9124 - loss: 0.4624\n",
      "Epoch 249: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9127 - loss: 0.4616 - val_accuracy: 0.7320 - val_loss: 1.2931\n",
      "Epoch 250/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9208 - loss: 0.4466\n",
      "Epoch 250: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9208 - loss: 0.4465 - val_accuracy: 0.7360 - val_loss: 1.2586\n",
      "Epoch 251/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9242 - loss: 0.4224\n",
      "Epoch 251: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9241 - loss: 0.4230 - val_accuracy: 0.7480 - val_loss: 1.2829\n",
      "Epoch 252/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9297 - loss: 0.4321\n",
      "Epoch 252: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9297 - loss: 0.4323 - val_accuracy: 0.7120 - val_loss: 1.3242\n",
      "Epoch 253/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9347 - loss: 0.4266\n",
      "Epoch 253: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9345 - loss: 0.4272 - val_accuracy: 0.7160 - val_loss: 1.3768\n",
      "Epoch 254/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9230 - loss: 0.4459\n",
      "Epoch 254: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9231 - loss: 0.4457 - val_accuracy: 0.7200 - val_loss: 1.3902\n",
      "Epoch 255/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9293 - loss: 0.4187\n",
      "Epoch 255: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9290 - loss: 0.4195 - val_accuracy: 0.7280 - val_loss: 1.2762\n",
      "Epoch 256/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9274 - loss: 0.4370\n",
      "Epoch 256: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9274 - loss: 0.4371 - val_accuracy: 0.7480 - val_loss: 1.3103\n",
      "Epoch 257/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9234 - loss: 0.4266\n",
      "Epoch 257: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9231 - loss: 0.4278 - val_accuracy: 0.7120 - val_loss: 1.3726\n",
      "Epoch 258/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9334 - loss: 0.4280\n",
      "Epoch 258: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9336 - loss: 0.4280 - val_accuracy: 0.7040 - val_loss: 1.3218\n",
      "Epoch 259/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9264 - loss: 0.4518\n",
      "Epoch 259: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9263 - loss: 0.4517 - val_accuracy: 0.6960 - val_loss: 1.3142\n",
      "Epoch 260/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9308 - loss: 0.4195\n",
      "Epoch 260: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9305 - loss: 0.4208 - val_accuracy: 0.7240 - val_loss: 1.3804\n",
      "Epoch 261/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9279 - loss: 0.4401\n",
      "Epoch 261: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9276 - loss: 0.4409 - val_accuracy: 0.7120 - val_loss: 1.2619\n",
      "Epoch 262/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9141 - loss: 0.4491\n",
      "Epoch 262: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9142 - loss: 0.4492 - val_accuracy: 0.7160 - val_loss: 1.3106\n",
      "Epoch 263/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9345 - loss: 0.4198\n",
      "Epoch 263: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9344 - loss: 0.4203 - val_accuracy: 0.7320 - val_loss: 1.2445\n",
      "Epoch 264/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9044 - loss: 0.5038\n",
      "Epoch 264: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9051 - loss: 0.5022 - val_accuracy: 0.6920 - val_loss: 1.3487\n",
      "Epoch 265/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9462 - loss: 0.3920\n",
      "Epoch 265: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9461 - loss: 0.3924 - val_accuracy: 0.7200 - val_loss: 1.2846\n",
      "Epoch 266/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9294 - loss: 0.4371\n",
      "Epoch 266: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9294 - loss: 0.4367 - val_accuracy: 0.7320 - val_loss: 1.2669\n",
      "Epoch 267/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9336 - loss: 0.4116\n",
      "Epoch 267: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9340 - loss: 0.4113 - val_accuracy: 0.7240 - val_loss: 1.2205\n",
      "Epoch 268/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9192 - loss: 0.4597\n",
      "Epoch 268: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9191 - loss: 0.4601 - val_accuracy: 0.7320 - val_loss: 1.2451\n",
      "Epoch 269/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9250 - loss: 0.4412\n",
      "Epoch 269: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9251 - loss: 0.4411 - val_accuracy: 0.7360 - val_loss: 1.2332\n",
      "Epoch 270/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9257 - loss: 0.4431\n",
      "Epoch 270: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9258 - loss: 0.4429 - val_accuracy: 0.7200 - val_loss: 1.2736\n",
      "Epoch 271/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9321 - loss: 0.4408\n",
      "Epoch 271: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9320 - loss: 0.4410 - val_accuracy: 0.6960 - val_loss: 1.2990\n",
      "Epoch 272/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9252 - loss: 0.4376\n",
      "Epoch 272: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9251 - loss: 0.4380 - val_accuracy: 0.6800 - val_loss: 1.4785\n",
      "Epoch 273/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9303 - loss: 0.4240\n",
      "Epoch 273: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9303 - loss: 0.4243 - val_accuracy: 0.7280 - val_loss: 1.2531\n",
      "Epoch 274/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9156 - loss: 0.4491\n",
      "Epoch 274: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.9157 - loss: 0.4494 - val_accuracy: 0.7400 - val_loss: 1.2864\n",
      "Epoch 275/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9237 - loss: 0.4555\n",
      "Epoch 275: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9238 - loss: 0.4551 - val_accuracy: 0.7360 - val_loss: 1.2668\n",
      "Epoch 276/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9395 - loss: 0.4152\n",
      "Epoch 276: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9395 - loss: 0.4153 - val_accuracy: 0.7120 - val_loss: 1.3739\n",
      "Epoch 277/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9295 - loss: 0.4315\n",
      "Epoch 277: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9295 - loss: 0.4315 - val_accuracy: 0.7160 - val_loss: 1.3324\n",
      "Epoch 278/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9347 - loss: 0.4250\n",
      "Epoch 278: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9344 - loss: 0.4258 - val_accuracy: 0.7360 - val_loss: 1.3506\n",
      "Epoch 279/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9339 - loss: 0.4339\n",
      "Epoch 279: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9338 - loss: 0.4342 - val_accuracy: 0.7360 - val_loss: 1.3770\n",
      "Epoch 280/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9307 - loss: 0.4521\n",
      "Epoch 280: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9308 - loss: 0.4515 - val_accuracy: 0.7120 - val_loss: 1.4466\n",
      "Epoch 281/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9430 - loss: 0.4150\n",
      "Epoch 281: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9427 - loss: 0.4156 - val_accuracy: 0.7240 - val_loss: 1.2733\n",
      "Epoch 282/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9327 - loss: 0.4311\n",
      "Epoch 282: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9325 - loss: 0.4313 - val_accuracy: 0.6920 - val_loss: 1.3348\n",
      "Epoch 283/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9087 - loss: 0.4726\n",
      "Epoch 283: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9090 - loss: 0.4727 - val_accuracy: 0.7320 - val_loss: 1.2446\n",
      "Epoch 284/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9261 - loss: 0.4309\n",
      "Epoch 284: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9260 - loss: 0.4308 - val_accuracy: 0.7320 - val_loss: 1.2886\n",
      "Epoch 285/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9245 - loss: 0.4443\n",
      "Epoch 285: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9245 - loss: 0.4441 - val_accuracy: 0.7200 - val_loss: 1.3026\n",
      "Epoch 286/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9420 - loss: 0.4015\n",
      "Epoch 286: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9418 - loss: 0.4018 - val_accuracy: 0.7200 - val_loss: 1.2801\n",
      "Epoch 287/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9254 - loss: 0.4120\n",
      "Epoch 287: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9257 - loss: 0.4121 - val_accuracy: 0.7320 - val_loss: 1.2718\n",
      "Epoch 288/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9185 - loss: 0.4664\n",
      "Epoch 288: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9189 - loss: 0.4655 - val_accuracy: 0.7040 - val_loss: 1.3276\n",
      "Epoch 289/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9264 - loss: 0.4430\n",
      "Epoch 289: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9263 - loss: 0.4428 - val_accuracy: 0.7080 - val_loss: 1.3020\n",
      "Epoch 290/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9199 - loss: 0.4621\n",
      "Epoch 290: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9201 - loss: 0.4615 - val_accuracy: 0.7440 - val_loss: 1.1974\n",
      "Epoch 291/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9379 - loss: 0.4134\n",
      "Epoch 291: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9376 - loss: 0.4138 - val_accuracy: 0.6920 - val_loss: 1.2972\n",
      "Epoch 292/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9448 - loss: 0.3960\n",
      "Epoch 292: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9447 - loss: 0.3961 - val_accuracy: 0.7480 - val_loss: 1.2739\n",
      "Epoch 293/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9392 - loss: 0.4247\n",
      "Epoch 293: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9390 - loss: 0.4248 - val_accuracy: 0.7320 - val_loss: 1.2433\n",
      "Epoch 294/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9312 - loss: 0.4067\n",
      "Epoch 294: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9312 - loss: 0.4069 - val_accuracy: 0.7360 - val_loss: 1.2801\n",
      "Epoch 295/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9330 - loss: 0.3983\n",
      "Epoch 295: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9328 - loss: 0.3993 - val_accuracy: 0.7240 - val_loss: 1.3255\n",
      "Epoch 296/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9325 - loss: 0.4292\n",
      "Epoch 296: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9322 - loss: 0.4295 - val_accuracy: 0.7440 - val_loss: 1.2676\n",
      "Epoch 297/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9358 - loss: 0.4217\n",
      "Epoch 297: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9355 - loss: 0.4220 - val_accuracy: 0.7400 - val_loss: 1.2686\n",
      "Epoch 298/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9263 - loss: 0.4278\n",
      "Epoch 298: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9262 - loss: 0.4280 - val_accuracy: 0.7120 - val_loss: 1.3239\n",
      "Epoch 299/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9241 - loss: 0.4311\n",
      "Epoch 299: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9241 - loss: 0.4311 - val_accuracy: 0.7320 - val_loss: 1.2868\n",
      "Epoch 300/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9294 - loss: 0.4216\n",
      "Epoch 300: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9292 - loss: 0.4222 - val_accuracy: 0.7120 - val_loss: 1.2565\n",
      "Epoch 301/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9369 - loss: 0.4234\n",
      "Epoch 301: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9369 - loss: 0.4235 - val_accuracy: 0.7440 - val_loss: 1.3149\n",
      "Epoch 302/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9440 - loss: 0.3911\n",
      "Epoch 302: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9435 - loss: 0.3924 - val_accuracy: 0.7200 - val_loss: 1.3544\n",
      "Epoch 303/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9424 - loss: 0.4060\n",
      "Epoch 303: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9423 - loss: 0.4063 - val_accuracy: 0.7360 - val_loss: 1.2774\n",
      "Epoch 304/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9349 - loss: 0.4390\n",
      "Epoch 304: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9349 - loss: 0.4390 - val_accuracy: 0.7040 - val_loss: 1.3118\n",
      "Epoch 305/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9285 - loss: 0.4359\n",
      "Epoch 305: val_accuracy did not improve from 0.74800\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9286 - loss: 0.4354 - val_accuracy: 0.7320 - val_loss: 1.2730\n",
      "Epoch 306/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9274 - loss: 0.4484\n",
      "Epoch 306: val_accuracy improved from 0.74800 to 0.75200, saving model to C:\\Users\\Zamskie\\Documents\\jason 3rd year\\2ND SEM\\cpe emerging\\bestModel\\best_model2.keras\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9274 - loss: 0.4481 - val_accuracy: 0.7520 - val_loss: 1.1982\n",
      "Epoch 307/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9176 - loss: 0.4418\n",
      "Epoch 307: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9176 - loss: 0.4426 - val_accuracy: 0.6880 - val_loss: 1.4186\n",
      "Epoch 308/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9344 - loss: 0.4101\n",
      "Epoch 308: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9341 - loss: 0.4114 - val_accuracy: 0.7440 - val_loss: 1.3478\n",
      "Epoch 309/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9357 - loss: 0.4271\n",
      "Epoch 309: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9355 - loss: 0.4277 - val_accuracy: 0.7200 - val_loss: 1.3066\n",
      "Epoch 310/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9407 - loss: 0.4103\n",
      "Epoch 310: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9404 - loss: 0.4109 - val_accuracy: 0.7120 - val_loss: 1.4127\n",
      "Epoch 311/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9369 - loss: 0.4170\n",
      "Epoch 311: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9365 - loss: 0.4180 - val_accuracy: 0.7400 - val_loss: 1.3440\n",
      "Epoch 312/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9293 - loss: 0.4430\n",
      "Epoch 312: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9294 - loss: 0.4427 - val_accuracy: 0.7200 - val_loss: 1.3146\n",
      "Epoch 313/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9376 - loss: 0.4100\n",
      "Epoch 313: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9376 - loss: 0.4101 - val_accuracy: 0.7240 - val_loss: 1.3396\n",
      "Epoch 314/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9339 - loss: 0.4184\n",
      "Epoch 314: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9337 - loss: 0.4184 - val_accuracy: 0.7280 - val_loss: 1.3068\n",
      "Epoch 315/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9260 - loss: 0.4227\n",
      "Epoch 315: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9262 - loss: 0.4224 - val_accuracy: 0.7120 - val_loss: 1.3726\n",
      "Epoch 316/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9309 - loss: 0.4241\n",
      "Epoch 316: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9310 - loss: 0.4235 - val_accuracy: 0.7160 - val_loss: 1.3672\n",
      "Epoch 317/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9422 - loss: 0.3818\n",
      "Epoch 317: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9421 - loss: 0.3823 - val_accuracy: 0.7280 - val_loss: 1.3488\n",
      "Epoch 318/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9327 - loss: 0.4050\n",
      "Epoch 318: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9326 - loss: 0.4052 - val_accuracy: 0.7280 - val_loss: 1.3281\n",
      "Epoch 319/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9268 - loss: 0.4205\n",
      "Epoch 319: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9269 - loss: 0.4203 - val_accuracy: 0.7240 - val_loss: 1.3981\n",
      "Epoch 320/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9386 - loss: 0.3948\n",
      "Epoch 320: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9385 - loss: 0.3956 - val_accuracy: 0.7000 - val_loss: 1.3755\n",
      "Epoch 321/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9262 - loss: 0.4322\n",
      "Epoch 321: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9258 - loss: 0.4330 - val_accuracy: 0.7080 - val_loss: 1.2936\n",
      "Epoch 322/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9316 - loss: 0.4155\n",
      "Epoch 322: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9315 - loss: 0.4157 - val_accuracy: 0.7280 - val_loss: 1.2559\n",
      "Epoch 323/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9215 - loss: 0.4391\n",
      "Epoch 323: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9216 - loss: 0.4389 - val_accuracy: 0.7280 - val_loss: 1.3125\n",
      "Epoch 324/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9396 - loss: 0.4080\n",
      "Epoch 324: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9392 - loss: 0.4087 - val_accuracy: 0.7120 - val_loss: 1.3008\n",
      "Epoch 325/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9388 - loss: 0.4253\n",
      "Epoch 325: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9387 - loss: 0.4251 - val_accuracy: 0.7000 - val_loss: 1.3901\n",
      "Epoch 326/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9426 - loss: 0.3883\n",
      "Epoch 326: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9426 - loss: 0.3884 - val_accuracy: 0.7360 - val_loss: 1.2931\n",
      "Epoch 327/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9318 - loss: 0.4044\n",
      "Epoch 327: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9318 - loss: 0.4050 - val_accuracy: 0.7120 - val_loss: 1.3619\n",
      "Epoch 328/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9422 - loss: 0.4075\n",
      "Epoch 328: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9419 - loss: 0.4077 - val_accuracy: 0.7000 - val_loss: 1.4063\n",
      "Epoch 329/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9381 - loss: 0.3980\n",
      "Epoch 329: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9383 - loss: 0.3977 - val_accuracy: 0.6760 - val_loss: 1.4324\n",
      "Epoch 330/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9466 - loss: 0.3899\n",
      "Epoch 330: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9464 - loss: 0.3898 - val_accuracy: 0.7240 - val_loss: 1.3017\n",
      "Epoch 331/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9407 - loss: 0.3854\n",
      "Epoch 331: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9405 - loss: 0.3851 - val_accuracy: 0.7040 - val_loss: 1.4041\n",
      "Epoch 332/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9398 - loss: 0.3976\n",
      "Epoch 332: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9396 - loss: 0.3984 - val_accuracy: 0.7240 - val_loss: 1.3976\n",
      "Epoch 333/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9315 - loss: 0.4010\n",
      "Epoch 333: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9316 - loss: 0.4009 - val_accuracy: 0.7120 - val_loss: 1.3508\n",
      "Epoch 334/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9334 - loss: 0.4128\n",
      "Epoch 334: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9332 - loss: 0.4139 - val_accuracy: 0.6720 - val_loss: 1.4985\n",
      "Epoch 335/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9327 - loss: 0.4217\n",
      "Epoch 335: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9327 - loss: 0.4219 - val_accuracy: 0.7360 - val_loss: 1.3199\n",
      "Epoch 336/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9459 - loss: 0.3904\n",
      "Epoch 336: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9458 - loss: 0.3907 - val_accuracy: 0.7280 - val_loss: 1.2963\n",
      "Epoch 337/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9349 - loss: 0.4054\n",
      "Epoch 337: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9347 - loss: 0.4061 - val_accuracy: 0.7080 - val_loss: 1.3174\n",
      "Epoch 338/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9135 - loss: 0.4558\n",
      "Epoch 338: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9139 - loss: 0.4547 - val_accuracy: 0.7040 - val_loss: 1.4836\n",
      "Epoch 339/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9423 - loss: 0.3952\n",
      "Epoch 339: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9422 - loss: 0.3958 - val_accuracy: 0.7080 - val_loss: 1.4085\n",
      "Epoch 340/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9226 - loss: 0.4208\n",
      "Epoch 340: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9227 - loss: 0.4206 - val_accuracy: 0.7240 - val_loss: 1.4364\n",
      "Epoch 341/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9353 - loss: 0.4064\n",
      "Epoch 341: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9354 - loss: 0.4059 - val_accuracy: 0.7360 - val_loss: 1.2808\n",
      "Epoch 342/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9387 - loss: 0.4074\n",
      "Epoch 342: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9384 - loss: 0.4078 - val_accuracy: 0.7080 - val_loss: 1.4102\n",
      "Epoch 343/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9366 - loss: 0.4083\n",
      "Epoch 343: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9366 - loss: 0.4085 - val_accuracy: 0.7320 - val_loss: 1.3741\n",
      "Epoch 344/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9433 - loss: 0.3906\n",
      "Epoch 344: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9431 - loss: 0.3910 - val_accuracy: 0.7040 - val_loss: 1.3671\n",
      "Epoch 345/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9408 - loss: 0.4032\n",
      "Epoch 345: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9407 - loss: 0.4035 - val_accuracy: 0.7280 - val_loss: 1.3225\n",
      "Epoch 346/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9389 - loss: 0.3961\n",
      "Epoch 346: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9388 - loss: 0.3962 - val_accuracy: 0.7160 - val_loss: 1.4364\n",
      "Epoch 347/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9516 - loss: 0.3679\n",
      "Epoch 347: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9516 - loss: 0.3680 - val_accuracy: 0.7440 - val_loss: 1.2959\n",
      "Epoch 348/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9431 - loss: 0.3891\n",
      "Epoch 348: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9430 - loss: 0.3893 - val_accuracy: 0.7360 - val_loss: 1.3070\n",
      "Epoch 349/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9288 - loss: 0.4335\n",
      "Epoch 349: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9290 - loss: 0.4327 - val_accuracy: 0.7360 - val_loss: 1.3074\n",
      "Epoch 350/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9446 - loss: 0.3876\n",
      "Epoch 350: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9442 - loss: 0.3884 - val_accuracy: 0.7200 - val_loss: 1.2952\n",
      "Epoch 351/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9322 - loss: 0.4029\n",
      "Epoch 351: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9323 - loss: 0.4027 - val_accuracy: 0.7240 - val_loss: 1.3158\n",
      "Epoch 352/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9229 - loss: 0.4483\n",
      "Epoch 352: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9230 - loss: 0.4476 - val_accuracy: 0.7240 - val_loss: 1.3171\n",
      "Epoch 353/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9345 - loss: 0.4055\n",
      "Epoch 353: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9345 - loss: 0.4058 - val_accuracy: 0.7360 - val_loss: 1.2705\n",
      "Epoch 354/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9447 - loss: 0.3851\n",
      "Epoch 354: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9445 - loss: 0.3856 - val_accuracy: 0.7440 - val_loss: 1.3414\n",
      "Epoch 355/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9336 - loss: 0.4289\n",
      "Epoch 355: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9332 - loss: 0.4289 - val_accuracy: 0.7440 - val_loss: 1.4198\n",
      "Epoch 356/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9363 - loss: 0.4098\n",
      "Epoch 356: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9363 - loss: 0.4099 - val_accuracy: 0.7280 - val_loss: 1.3525\n",
      "Epoch 357/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9363 - loss: 0.3843\n",
      "Epoch 357: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9364 - loss: 0.3845 - val_accuracy: 0.7120 - val_loss: 1.3549\n",
      "Epoch 358/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9307 - loss: 0.4321\n",
      "Epoch 358: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9306 - loss: 0.4316 - val_accuracy: 0.6960 - val_loss: 1.4015\n",
      "Epoch 359/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9330 - loss: 0.4005\n",
      "Epoch 359: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9331 - loss: 0.4004 - val_accuracy: 0.7160 - val_loss: 1.3101\n",
      "Epoch 360/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9385 - loss: 0.4056\n",
      "Epoch 360: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9384 - loss: 0.4057 - val_accuracy: 0.7200 - val_loss: 1.3609\n",
      "Epoch 361/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9396 - loss: 0.4004\n",
      "Epoch 361: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9396 - loss: 0.4004 - val_accuracy: 0.6920 - val_loss: 1.4386\n",
      "Epoch 362/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9403 - loss: 0.3941\n",
      "Epoch 362: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9400 - loss: 0.3950 - val_accuracy: 0.7160 - val_loss: 1.3440\n",
      "Epoch 363/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9410 - loss: 0.3860\n",
      "Epoch 363: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9408 - loss: 0.3869 - val_accuracy: 0.7120 - val_loss: 1.4160\n",
      "Epoch 364/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9257 - loss: 0.4372\n",
      "Epoch 364: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9257 - loss: 0.4371 - val_accuracy: 0.7200 - val_loss: 1.3306\n",
      "Epoch 365/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9297 - loss: 0.4182\n",
      "Epoch 365: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9300 - loss: 0.4175 - val_accuracy: 0.7240 - val_loss: 1.3812\n",
      "Epoch 366/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9181 - loss: 0.4362\n",
      "Epoch 366: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9186 - loss: 0.4350 - val_accuracy: 0.7360 - val_loss: 1.3551\n",
      "Epoch 367/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9461 - loss: 0.3836\n",
      "Epoch 367: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9461 - loss: 0.3835 - val_accuracy: 0.7240 - val_loss: 1.3196\n",
      "Epoch 368/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9539 - loss: 0.3501\n",
      "Epoch 368: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9537 - loss: 0.3506 - val_accuracy: 0.7280 - val_loss: 1.3237\n",
      "Epoch 369/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9529 - loss: 0.3563\n",
      "Epoch 369: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9526 - loss: 0.3568 - val_accuracy: 0.7360 - val_loss: 1.3523\n",
      "Epoch 370/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9544 - loss: 0.3560\n",
      "Epoch 370: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9543 - loss: 0.3562 - val_accuracy: 0.7400 - val_loss: 1.2997\n",
      "Epoch 371/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9330 - loss: 0.4103\n",
      "Epoch 371: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9330 - loss: 0.4101 - val_accuracy: 0.7160 - val_loss: 1.3772\n",
      "Epoch 372/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9301 - loss: 0.4093\n",
      "Epoch 372: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9300 - loss: 0.4098 - val_accuracy: 0.7400 - val_loss: 1.2658\n",
      "Epoch 373/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9188 - loss: 0.4198\n",
      "Epoch 373: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9188 - loss: 0.4201 - val_accuracy: 0.7240 - val_loss: 1.3032\n",
      "Epoch 374/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9465 - loss: 0.3737\n",
      "Epoch 374: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9463 - loss: 0.3745 - val_accuracy: 0.7400 - val_loss: 1.2843\n",
      "Epoch 375/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9239 - loss: 0.4377\n",
      "Epoch 375: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9235 - loss: 0.4384 - val_accuracy: 0.7240 - val_loss: 1.2365\n",
      "Epoch 376/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9317 - loss: 0.4117\n",
      "Epoch 376: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9315 - loss: 0.4126 - val_accuracy: 0.7040 - val_loss: 1.4357\n",
      "Epoch 377/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9450 - loss: 0.3976\n",
      "Epoch 377: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9447 - loss: 0.3979 - val_accuracy: 0.7320 - val_loss: 1.3497\n",
      "Epoch 378/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9371 - loss: 0.4346\n",
      "Epoch 378: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9374 - loss: 0.4334 - val_accuracy: 0.7280 - val_loss: 1.3768\n",
      "Epoch 379/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9360 - loss: 0.4078\n",
      "Epoch 379: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9359 - loss: 0.4078 - val_accuracy: 0.7040 - val_loss: 1.3268\n",
      "Epoch 380/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9236 - loss: 0.4272\n",
      "Epoch 380: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9238 - loss: 0.4269 - val_accuracy: 0.7160 - val_loss: 1.3148\n",
      "Epoch 381/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9353 - loss: 0.3967\n",
      "Epoch 381: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9353 - loss: 0.3969 - val_accuracy: 0.7000 - val_loss: 1.2781\n",
      "Epoch 382/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9458 - loss: 0.3846\n",
      "Epoch 382: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9456 - loss: 0.3846 - val_accuracy: 0.7280 - val_loss: 1.4334\n",
      "Epoch 383/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9437 - loss: 0.3814\n",
      "Epoch 383: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9437 - loss: 0.3814 - val_accuracy: 0.7200 - val_loss: 1.4285\n",
      "Epoch 384/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9355 - loss: 0.3976\n",
      "Epoch 384: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9355 - loss: 0.3976 - val_accuracy: 0.7280 - val_loss: 1.4199\n",
      "Epoch 385/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9477 - loss: 0.3675\n",
      "Epoch 385: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9473 - loss: 0.3691 - val_accuracy: 0.7360 - val_loss: 1.2856\n",
      "Epoch 386/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9374 - loss: 0.4026\n",
      "Epoch 386: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9374 - loss: 0.4025 - val_accuracy: 0.6960 - val_loss: 1.4944\n",
      "Epoch 387/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9295 - loss: 0.4130\n",
      "Epoch 387: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9295 - loss: 0.4128 - val_accuracy: 0.7440 - val_loss: 1.3727\n",
      "Epoch 388/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9383 - loss: 0.4078\n",
      "Epoch 388: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9382 - loss: 0.4081 - val_accuracy: 0.7200 - val_loss: 1.4234\n",
      "Epoch 389/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9339 - loss: 0.4028\n",
      "Epoch 389: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9340 - loss: 0.4028 - val_accuracy: 0.7200 - val_loss: 1.4027\n",
      "Epoch 390/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9361 - loss: 0.3959\n",
      "Epoch 390: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9365 - loss: 0.3950 - val_accuracy: 0.7200 - val_loss: 1.3726\n",
      "Epoch 391/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9395 - loss: 0.3804\n",
      "Epoch 391: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9398 - loss: 0.3803 - val_accuracy: 0.7000 - val_loss: 1.3045\n",
      "Epoch 392/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9324 - loss: 0.3971\n",
      "Epoch 392: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9324 - loss: 0.3971 - val_accuracy: 0.7120 - val_loss: 1.3632\n",
      "Epoch 393/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9436 - loss: 0.3959\n",
      "Epoch 393: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9434 - loss: 0.3958 - val_accuracy: 0.7320 - val_loss: 1.4367\n",
      "Epoch 394/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9318 - loss: 0.4034\n",
      "Epoch 394: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9316 - loss: 0.4043 - val_accuracy: 0.7360 - val_loss: 1.3875\n",
      "Epoch 395/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9458 - loss: 0.3908\n",
      "Epoch 395: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9455 - loss: 0.3913 - val_accuracy: 0.7200 - val_loss: 1.3407\n",
      "Epoch 396/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9285 - loss: 0.4358\n",
      "Epoch 396: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9286 - loss: 0.4357 - val_accuracy: 0.7280 - val_loss: 1.3518\n",
      "Epoch 397/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9462 - loss: 0.3826\n",
      "Epoch 397: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9461 - loss: 0.3828 - val_accuracy: 0.7080 - val_loss: 1.4180\n",
      "Epoch 398/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9372 - loss: 0.4003\n",
      "Epoch 398: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9372 - loss: 0.4006 - val_accuracy: 0.7200 - val_loss: 1.4140\n",
      "Epoch 399/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9374 - loss: 0.4004\n",
      "Epoch 399: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9374 - loss: 0.4007 - val_accuracy: 0.6840 - val_loss: 1.5022\n",
      "Epoch 400/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9492 - loss: 0.3615\n",
      "Epoch 400: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9488 - loss: 0.3623 - val_accuracy: 0.7400 - val_loss: 1.3186\n",
      "Epoch 401/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9479 - loss: 0.3659\n",
      "Epoch 401: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9477 - loss: 0.3665 - val_accuracy: 0.7200 - val_loss: 1.3888\n",
      "Epoch 402/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9377 - loss: 0.3917\n",
      "Epoch 402: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9377 - loss: 0.3921 - val_accuracy: 0.6480 - val_loss: 1.6121\n",
      "Epoch 403/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9315 - loss: 0.4011\n",
      "Epoch 403: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9314 - loss: 0.4011 - val_accuracy: 0.7000 - val_loss: 1.3955\n",
      "Epoch 404/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9312 - loss: 0.4068\n",
      "Epoch 404: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9313 - loss: 0.4071 - val_accuracy: 0.6760 - val_loss: 1.5824\n",
      "Epoch 405/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9370 - loss: 0.4115\n",
      "Epoch 405: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9371 - loss: 0.4112 - val_accuracy: 0.7360 - val_loss: 1.3573\n",
      "Epoch 406/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9447 - loss: 0.3779\n",
      "Epoch 406: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9446 - loss: 0.3781 - val_accuracy: 0.7160 - val_loss: 1.3688\n",
      "Epoch 407/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9463 - loss: 0.3805\n",
      "Epoch 407: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9463 - loss: 0.3802 - val_accuracy: 0.7200 - val_loss: 1.2814\n",
      "Epoch 408/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9476 - loss: 0.3681\n",
      "Epoch 408: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9474 - loss: 0.3686 - val_accuracy: 0.7280 - val_loss: 1.3586\n",
      "Epoch 409/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9481 - loss: 0.3602\n",
      "Epoch 409: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9477 - loss: 0.3614 - val_accuracy: 0.7320 - val_loss: 1.3991\n",
      "Epoch 410/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9401 - loss: 0.3976\n",
      "Epoch 410: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9400 - loss: 0.3975 - val_accuracy: 0.7360 - val_loss: 1.2774\n",
      "Epoch 411/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9507 - loss: 0.3694\n",
      "Epoch 411: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9504 - loss: 0.3702 - val_accuracy: 0.7520 - val_loss: 1.2089\n",
      "Epoch 412/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9439 - loss: 0.3943\n",
      "Epoch 412: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9438 - loss: 0.3946 - val_accuracy: 0.7280 - val_loss: 1.2825\n",
      "Epoch 413/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9285 - loss: 0.4205\n",
      "Epoch 413: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9287 - loss: 0.4199 - val_accuracy: 0.6880 - val_loss: 1.4781\n",
      "Epoch 414/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9407 - loss: 0.3931\n",
      "Epoch 414: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9405 - loss: 0.3936 - val_accuracy: 0.7080 - val_loss: 1.4009\n",
      "Epoch 415/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9392 - loss: 0.3979\n",
      "Epoch 415: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9391 - loss: 0.3982 - val_accuracy: 0.7040 - val_loss: 1.3625\n",
      "Epoch 416/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9390 - loss: 0.3915\n",
      "Epoch 416: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9389 - loss: 0.3921 - val_accuracy: 0.7200 - val_loss: 1.3648\n",
      "Epoch 417/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9482 - loss: 0.3756\n",
      "Epoch 417: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9479 - loss: 0.3761 - val_accuracy: 0.7280 - val_loss: 1.4475\n",
      "Epoch 418/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9426 - loss: 0.3981\n",
      "Epoch 418: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9423 - loss: 0.3984 - val_accuracy: 0.7160 - val_loss: 1.3245\n",
      "Epoch 419/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9273 - loss: 0.4207\n",
      "Epoch 419: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9277 - loss: 0.4204 - val_accuracy: 0.7000 - val_loss: 1.4293\n",
      "Epoch 420/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9337 - loss: 0.3903\n",
      "Epoch 420: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9338 - loss: 0.3904 - val_accuracy: 0.7280 - val_loss: 1.3426\n",
      "Epoch 421/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9392 - loss: 0.3902\n",
      "Epoch 421: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9392 - loss: 0.3905 - val_accuracy: 0.7320 - val_loss: 1.3339\n",
      "Epoch 422/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9396 - loss: 0.4019\n",
      "Epoch 422: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9398 - loss: 0.4017 - val_accuracy: 0.7160 - val_loss: 1.4106\n",
      "Epoch 423/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9317 - loss: 0.4239\n",
      "Epoch 423: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9319 - loss: 0.4234 - val_accuracy: 0.7200 - val_loss: 1.3567\n",
      "Epoch 424/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9465 - loss: 0.3717\n",
      "Epoch 424: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9464 - loss: 0.3718 - val_accuracy: 0.7080 - val_loss: 1.4788\n",
      "Epoch 425/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9555 - loss: 0.3736\n",
      "Epoch 425: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9552 - loss: 0.3742 - val_accuracy: 0.7080 - val_loss: 1.4422\n",
      "Epoch 426/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9568 - loss: 0.3521\n",
      "Epoch 426: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9566 - loss: 0.3524 - val_accuracy: 0.7120 - val_loss: 1.3805\n",
      "Epoch 427/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9310 - loss: 0.3786\n",
      "Epoch 427: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9313 - loss: 0.3788 - val_accuracy: 0.7000 - val_loss: 1.2976\n",
      "Epoch 428/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9407 - loss: 0.3861\n",
      "Epoch 428: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9407 - loss: 0.3868 - val_accuracy: 0.7440 - val_loss: 1.2538\n",
      "Epoch 429/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9497 - loss: 0.3682\n",
      "Epoch 429: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9495 - loss: 0.3682 - val_accuracy: 0.7040 - val_loss: 1.3224\n",
      "Epoch 430/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9516 - loss: 0.3535\n",
      "Epoch 430: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9512 - loss: 0.3548 - val_accuracy: 0.7000 - val_loss: 1.3552\n",
      "Epoch 431/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9388 - loss: 0.3984\n",
      "Epoch 431: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9390 - loss: 0.3974 - val_accuracy: 0.7080 - val_loss: 1.3125\n",
      "Epoch 432/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9596 - loss: 0.3546\n",
      "Epoch 432: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9590 - loss: 0.3559 - val_accuracy: 0.6320 - val_loss: 1.6512\n",
      "Epoch 433/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9426 - loss: 0.3932\n",
      "Epoch 433: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9425 - loss: 0.3932 - val_accuracy: 0.7240 - val_loss: 1.2841\n",
      "Epoch 434/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9451 - loss: 0.3596\n",
      "Epoch 434: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9450 - loss: 0.3599 - val_accuracy: 0.7280 - val_loss: 1.3191\n",
      "Epoch 435/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9417 - loss: 0.3674\n",
      "Epoch 435: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9415 - loss: 0.3687 - val_accuracy: 0.7160 - val_loss: 1.3195\n",
      "Epoch 436/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9213 - loss: 0.4191\n",
      "Epoch 436: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9213 - loss: 0.4193 - val_accuracy: 0.7080 - val_loss: 1.2676\n",
      "Epoch 437/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9422 - loss: 0.3858\n",
      "Epoch 437: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9420 - loss: 0.3862 - val_accuracy: 0.7240 - val_loss: 1.2660\n",
      "Epoch 438/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9423 - loss: 0.3861\n",
      "Epoch 438: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9421 - loss: 0.3861 - val_accuracy: 0.7320 - val_loss: 1.3578\n",
      "Epoch 439/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9493 - loss: 0.3635\n",
      "Epoch 439: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9493 - loss: 0.3637 - val_accuracy: 0.7040 - val_loss: 1.3914\n",
      "Epoch 440/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9459 - loss: 0.3529\n",
      "Epoch 440: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9458 - loss: 0.3537 - val_accuracy: 0.7280 - val_loss: 1.2413\n",
      "Epoch 441/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9469 - loss: 0.3476\n",
      "Epoch 441: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9466 - loss: 0.3484 - val_accuracy: 0.7200 - val_loss: 1.2773\n",
      "Epoch 442/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9402 - loss: 0.3772\n",
      "Epoch 442: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9403 - loss: 0.3767 - val_accuracy: 0.7440 - val_loss: 1.3606\n",
      "Epoch 443/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9396 - loss: 0.3924\n",
      "Epoch 443: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9396 - loss: 0.3922 - val_accuracy: 0.7320 - val_loss: 1.3691\n",
      "Epoch 444/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9452 - loss: 0.3584\n",
      "Epoch 444: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9451 - loss: 0.3588 - val_accuracy: 0.7240 - val_loss: 1.3262\n",
      "Epoch 445/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9333 - loss: 0.4020\n",
      "Epoch 445: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9335 - loss: 0.4017 - val_accuracy: 0.7160 - val_loss: 1.4076\n",
      "Epoch 446/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9527 - loss: 0.3510\n",
      "Epoch 446: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9524 - loss: 0.3514 - val_accuracy: 0.7080 - val_loss: 1.3705\n",
      "Epoch 447/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9473 - loss: 0.3704\n",
      "Epoch 447: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9470 - loss: 0.3712 - val_accuracy: 0.7360 - val_loss: 1.3485\n",
      "Epoch 448/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9324 - loss: 0.4168\n",
      "Epoch 448: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9326 - loss: 0.4161 - val_accuracy: 0.7280 - val_loss: 1.3181\n",
      "Epoch 449/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9448 - loss: 0.3777\n",
      "Epoch 449: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9448 - loss: 0.3779 - val_accuracy: 0.7440 - val_loss: 1.3202\n",
      "Epoch 450/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9480 - loss: 0.3637\n",
      "Epoch 450: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9476 - loss: 0.3646 - val_accuracy: 0.7280 - val_loss: 1.3786\n",
      "Epoch 451/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9444 - loss: 0.3738\n",
      "Epoch 451: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9441 - loss: 0.3743 - val_accuracy: 0.7240 - val_loss: 1.3473\n",
      "Epoch 452/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9347 - loss: 0.3937\n",
      "Epoch 452: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9347 - loss: 0.3935 - val_accuracy: 0.7320 - val_loss: 1.3614\n",
      "Epoch 453/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9587 - loss: 0.3386\n",
      "Epoch 453: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9584 - loss: 0.3391 - val_accuracy: 0.7280 - val_loss: 1.3779\n",
      "Epoch 454/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9563 - loss: 0.3420\n",
      "Epoch 454: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9559 - loss: 0.3427 - val_accuracy: 0.7000 - val_loss: 1.4080\n",
      "Epoch 455/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9404 - loss: 0.3782\n",
      "Epoch 455: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9405 - loss: 0.3780 - val_accuracy: 0.7240 - val_loss: 1.2449\n",
      "Epoch 456/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9393 - loss: 0.3943\n",
      "Epoch 456: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9393 - loss: 0.3938 - val_accuracy: 0.7240 - val_loss: 1.3593\n",
      "Epoch 457/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9524 - loss: 0.3648\n",
      "Epoch 457: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9523 - loss: 0.3651 - val_accuracy: 0.7400 - val_loss: 1.3997\n",
      "Epoch 458/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9364 - loss: 0.3925\n",
      "Epoch 458: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9364 - loss: 0.3922 - val_accuracy: 0.7160 - val_loss: 1.3929\n",
      "Epoch 459/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9407 - loss: 0.3773\n",
      "Epoch 459: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9404 - loss: 0.3782 - val_accuracy: 0.7160 - val_loss: 1.3237\n",
      "Epoch 460/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9413 - loss: 0.3914\n",
      "Epoch 460: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9411 - loss: 0.3924 - val_accuracy: 0.6560 - val_loss: 1.5735\n",
      "Epoch 461/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9514 - loss: 0.3574\n",
      "Epoch 461: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9513 - loss: 0.3578 - val_accuracy: 0.7040 - val_loss: 1.2970\n",
      "Epoch 462/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9403 - loss: 0.3809\n",
      "Epoch 462: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9401 - loss: 0.3816 - val_accuracy: 0.7080 - val_loss: 1.2580\n",
      "Epoch 463/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9379 - loss: 0.3831\n",
      "Epoch 463: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9379 - loss: 0.3833 - val_accuracy: 0.7360 - val_loss: 1.3086\n",
      "Epoch 464/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9394 - loss: 0.3949\n",
      "Epoch 464: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9395 - loss: 0.3949 - val_accuracy: 0.7160 - val_loss: 1.3019\n",
      "Epoch 465/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9493 - loss: 0.3619\n",
      "Epoch 465: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9492 - loss: 0.3620 - val_accuracy: 0.7040 - val_loss: 1.4307\n",
      "Epoch 466/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9460 - loss: 0.3811\n",
      "Epoch 466: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9459 - loss: 0.3811 - val_accuracy: 0.7200 - val_loss: 1.3685\n",
      "Epoch 467/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9434 - loss: 0.3639\n",
      "Epoch 467: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9435 - loss: 0.3638 - val_accuracy: 0.7240 - val_loss: 1.3228\n",
      "Epoch 468/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9454 - loss: 0.3610\n",
      "Epoch 468: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9453 - loss: 0.3615 - val_accuracy: 0.7200 - val_loss: 1.4141\n",
      "Epoch 469/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9435 - loss: 0.3673\n",
      "Epoch 469: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9434 - loss: 0.3671 - val_accuracy: 0.7200 - val_loss: 1.3328\n",
      "Epoch 470/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9383 - loss: 0.3574\n",
      "Epoch 470: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9383 - loss: 0.3578 - val_accuracy: 0.7160 - val_loss: 1.4086\n",
      "Epoch 471/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9296 - loss: 0.4065\n",
      "Epoch 471: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9301 - loss: 0.4054 - val_accuracy: 0.7160 - val_loss: 1.4530\n",
      "Epoch 472/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9372 - loss: 0.4030\n",
      "Epoch 472: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9371 - loss: 0.4029 - val_accuracy: 0.7320 - val_loss: 1.3970\n",
      "Epoch 473/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9446 - loss: 0.3923\n",
      "Epoch 473: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9446 - loss: 0.3920 - val_accuracy: 0.7240 - val_loss: 1.3225\n",
      "Epoch 474/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9391 - loss: 0.3807\n",
      "Epoch 474: val_accuracy did not improve from 0.75200\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9391 - loss: 0.3806 - val_accuracy: 0.7400 - val_loss: 1.4403\n",
      "Epoch 475/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9586 - loss: 0.3388\n",
      "Epoch 475: val_accuracy improved from 0.75200 to 0.75600, saving model to C:\\Users\\Zamskie\\Documents\\jason 3rd year\\2ND SEM\\cpe emerging\\bestModel\\best_model2.keras\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9582 - loss: 0.3396 - val_accuracy: 0.7560 - val_loss: 1.3328\n",
      "Epoch 476/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9519 - loss: 0.3599\n",
      "Epoch 476: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9516 - loss: 0.3609 - val_accuracy: 0.7040 - val_loss: 1.3811\n",
      "Epoch 477/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9366 - loss: 0.4099\n",
      "Epoch 477: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9369 - loss: 0.4091 - val_accuracy: 0.7360 - val_loss: 1.3330\n",
      "Epoch 478/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9385 - loss: 0.3795\n",
      "Epoch 478: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9383 - loss: 0.3796 - val_accuracy: 0.7440 - val_loss: 1.2648\n",
      "Epoch 479/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9477 - loss: 0.3720\n",
      "Epoch 479: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9474 - loss: 0.3722 - val_accuracy: 0.6480 - val_loss: 1.5580\n",
      "Epoch 480/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9421 - loss: 0.3982\n",
      "Epoch 480: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9423 - loss: 0.3975 - val_accuracy: 0.7360 - val_loss: 1.3603\n",
      "Epoch 481/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9465 - loss: 0.3630\n",
      "Epoch 481: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9466 - loss: 0.3628 - val_accuracy: 0.7200 - val_loss: 1.2894\n",
      "Epoch 482/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9371 - loss: 0.3824\n",
      "Epoch 482: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9374 - loss: 0.3820 - val_accuracy: 0.7240 - val_loss: 1.4705\n",
      "Epoch 483/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9486 - loss: 0.3507\n",
      "Epoch 483: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9484 - loss: 0.3513 - val_accuracy: 0.7240 - val_loss: 1.3934\n",
      "Epoch 484/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9531 - loss: 0.3484\n",
      "Epoch 484: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9529 - loss: 0.3493 - val_accuracy: 0.7240 - val_loss: 1.3226\n",
      "Epoch 485/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9510 - loss: 0.3536\n",
      "Epoch 485: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9508 - loss: 0.3542 - val_accuracy: 0.7320 - val_loss: 1.4576\n",
      "Epoch 486/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9476 - loss: 0.3558\n",
      "Epoch 486: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9475 - loss: 0.3562 - val_accuracy: 0.7520 - val_loss: 1.2861\n",
      "Epoch 487/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9541 - loss: 0.3531\n",
      "Epoch 487: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9539 - loss: 0.3534 - val_accuracy: 0.7360 - val_loss: 1.3006\n",
      "Epoch 488/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9560 - loss: 0.3542\n",
      "Epoch 488: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9558 - loss: 0.3545 - val_accuracy: 0.7440 - val_loss: 1.3348\n",
      "Epoch 489/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9428 - loss: 0.3596\n",
      "Epoch 489: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9425 - loss: 0.3603 - val_accuracy: 0.7360 - val_loss: 1.3479\n",
      "Epoch 490/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9368 - loss: 0.3750\n",
      "Epoch 490: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9368 - loss: 0.3749 - val_accuracy: 0.7520 - val_loss: 1.3449\n",
      "Epoch 491/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9462 - loss: 0.3706\n",
      "Epoch 491: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9461 - loss: 0.3705 - val_accuracy: 0.7240 - val_loss: 1.3385\n",
      "Epoch 492/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9561 - loss: 0.3399\n",
      "Epoch 492: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9558 - loss: 0.3411 - val_accuracy: 0.7120 - val_loss: 1.5850\n",
      "Epoch 493/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9552 - loss: 0.3493\n",
      "Epoch 493: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9550 - loss: 0.3502 - val_accuracy: 0.7440 - val_loss: 1.3260\n",
      "Epoch 494/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9459 - loss: 0.3727\n",
      "Epoch 494: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9460 - loss: 0.3725 - val_accuracy: 0.7120 - val_loss: 1.3804\n",
      "Epoch 495/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9337 - loss: 0.3793\n",
      "Epoch 495: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9339 - loss: 0.3792 - val_accuracy: 0.7440 - val_loss: 1.3674\n",
      "Epoch 496/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9405 - loss: 0.3806\n",
      "Epoch 496: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9404 - loss: 0.3811 - val_accuracy: 0.7200 - val_loss: 1.3347\n",
      "Epoch 497/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9402 - loss: 0.3769\n",
      "Epoch 497: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9405 - loss: 0.3760 - val_accuracy: 0.7200 - val_loss: 1.4529\n",
      "Epoch 498/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9521 - loss: 0.3539\n",
      "Epoch 498: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9520 - loss: 0.3541 - val_accuracy: 0.7480 - val_loss: 1.3053\n",
      "Epoch 499/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9461 - loss: 0.3733\n",
      "Epoch 499: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9458 - loss: 0.3735 - val_accuracy: 0.7360 - val_loss: 1.3268\n",
      "Epoch 500/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9534 - loss: 0.3563\n",
      "Epoch 500: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9533 - loss: 0.3561 - val_accuracy: 0.7400 - val_loss: 1.3234\n",
      "Epoch 501/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9398 - loss: 0.3615\n",
      "Epoch 501: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9398 - loss: 0.3616 - val_accuracy: 0.7520 - val_loss: 1.3013\n",
      "Epoch 502/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9373 - loss: 0.3787\n",
      "Epoch 502: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9376 - loss: 0.3782 - val_accuracy: 0.7440 - val_loss: 1.2459\n",
      "Epoch 503/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9389 - loss: 0.3668\n",
      "Epoch 503: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9387 - loss: 0.3672 - val_accuracy: 0.7160 - val_loss: 1.3438\n",
      "Epoch 504/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9570 - loss: 0.3499\n",
      "Epoch 504: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9569 - loss: 0.3505 - val_accuracy: 0.7320 - val_loss: 1.4192\n",
      "Epoch 505/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9320 - loss: 0.3846\n",
      "Epoch 505: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9320 - loss: 0.3850 - val_accuracy: 0.7240 - val_loss: 1.4172\n",
      "Epoch 506/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9472 - loss: 0.3706\n",
      "Epoch 506: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9469 - loss: 0.3714 - val_accuracy: 0.7160 - val_loss: 1.2861\n",
      "Epoch 507/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9450 - loss: 0.3693\n",
      "Epoch 507: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9450 - loss: 0.3695 - val_accuracy: 0.7240 - val_loss: 1.2776\n",
      "Epoch 508/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9415 - loss: 0.3850\n",
      "Epoch 508: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9415 - loss: 0.3850 - val_accuracy: 0.7360 - val_loss: 1.2724\n",
      "Epoch 509/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9493 - loss: 0.3432\n",
      "Epoch 509: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9491 - loss: 0.3443 - val_accuracy: 0.7280 - val_loss: 1.2228\n",
      "Epoch 510/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9491 - loss: 0.3508\n",
      "Epoch 510: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9493 - loss: 0.3507 - val_accuracy: 0.7360 - val_loss: 1.3011\n",
      "Epoch 511/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9432 - loss: 0.3723\n",
      "Epoch 511: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9432 - loss: 0.3727 - val_accuracy: 0.7320 - val_loss: 1.3528\n",
      "Epoch 512/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9427 - loss: 0.3701\n",
      "Epoch 512: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9427 - loss: 0.3700 - val_accuracy: 0.7240 - val_loss: 1.3809\n",
      "Epoch 513/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9400 - loss: 0.3728\n",
      "Epoch 513: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9397 - loss: 0.3738 - val_accuracy: 0.7440 - val_loss: 1.2942\n",
      "Epoch 514/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9487 - loss: 0.3534\n",
      "Epoch 514: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9488 - loss: 0.3534 - val_accuracy: 0.7320 - val_loss: 1.4131\n",
      "Epoch 515/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9431 - loss: 0.3759\n",
      "Epoch 515: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9430 - loss: 0.3766 - val_accuracy: 0.7360 - val_loss: 1.2842\n",
      "Epoch 516/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9445 - loss: 0.3602\n",
      "Epoch 516: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9444 - loss: 0.3608 - val_accuracy: 0.7120 - val_loss: 1.4189\n",
      "Epoch 517/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9347 - loss: 0.4067\n",
      "Epoch 517: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9348 - loss: 0.4060 - val_accuracy: 0.7280 - val_loss: 1.1849\n",
      "Epoch 518/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9568 - loss: 0.3446\n",
      "Epoch 518: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9567 - loss: 0.3448 - val_accuracy: 0.7400 - val_loss: 1.2423\n",
      "Epoch 519/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9481 - loss: 0.3580\n",
      "Epoch 519: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9481 - loss: 0.3580 - val_accuracy: 0.7240 - val_loss: 1.2692\n",
      "Epoch 520/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9421 - loss: 0.3655\n",
      "Epoch 520: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9422 - loss: 0.3655 - val_accuracy: 0.7480 - val_loss: 1.2384\n",
      "Epoch 521/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9543 - loss: 0.3411\n",
      "Epoch 521: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9542 - loss: 0.3412 - val_accuracy: 0.7280 - val_loss: 1.2866\n",
      "Epoch 522/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9544 - loss: 0.3483\n",
      "Epoch 522: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9541 - loss: 0.3484 - val_accuracy: 0.7400 - val_loss: 1.2754\n",
      "Epoch 523/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9581 - loss: 0.3268\n",
      "Epoch 523: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9578 - loss: 0.3270 - val_accuracy: 0.7440 - val_loss: 1.3796\n",
      "Epoch 524/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9444 - loss: 0.3451\n",
      "Epoch 524: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9444 - loss: 0.3452 - val_accuracy: 0.7440 - val_loss: 1.2953\n",
      "Epoch 525/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9498 - loss: 0.3438\n",
      "Epoch 525: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9496 - loss: 0.3442 - val_accuracy: 0.7440 - val_loss: 1.3430\n",
      "Epoch 526/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9481 - loss: 0.3344\n",
      "Epoch 526: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9479 - loss: 0.3347 - val_accuracy: 0.7120 - val_loss: 1.3396\n",
      "Epoch 527/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9443 - loss: 0.3725\n",
      "Epoch 527: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9446 - loss: 0.3719 - val_accuracy: 0.7400 - val_loss: 1.2882\n",
      "Epoch 528/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9516 - loss: 0.3321\n",
      "Epoch 528: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9516 - loss: 0.3324 - val_accuracy: 0.7400 - val_loss: 1.2641\n",
      "Epoch 529/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9489 - loss: 0.3430\n",
      "Epoch 529: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9490 - loss: 0.3429 - val_accuracy: 0.7240 - val_loss: 1.3881\n",
      "Epoch 530/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9481 - loss: 0.3356\n",
      "Epoch 530: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9481 - loss: 0.3361 - val_accuracy: 0.7360 - val_loss: 1.3646\n",
      "Epoch 531/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9476 - loss: 0.3499\n",
      "Epoch 531: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9476 - loss: 0.3500 - val_accuracy: 0.7320 - val_loss: 1.3850\n",
      "Epoch 532/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9471 - loss: 0.3467\n",
      "Epoch 532: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9471 - loss: 0.3469 - val_accuracy: 0.7400 - val_loss: 1.3323\n",
      "Epoch 533/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9385 - loss: 0.3746\n",
      "Epoch 533: val_accuracy did not improve from 0.75600\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9385 - loss: 0.3745 - val_accuracy: 0.7280 - val_loss: 1.3476\n",
      "Epoch 534/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9430 - loss: 0.3632\n",
      "Epoch 534: val_accuracy improved from 0.75600 to 0.76400, saving model to C:\\Users\\Zamskie\\Documents\\jason 3rd year\\2ND SEM\\cpe emerging\\bestModel\\best_model2.keras\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9431 - loss: 0.3631 - val_accuracy: 0.7640 - val_loss: 1.2682\n",
      "Epoch 535/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9506 - loss: 0.3479\n",
      "Epoch 535: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9506 - loss: 0.3479 - val_accuracy: 0.7320 - val_loss: 1.3343\n",
      "Epoch 536/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9582 - loss: 0.3309\n",
      "Epoch 536: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9582 - loss: 0.3309 - val_accuracy: 0.7240 - val_loss: 1.3068\n",
      "Epoch 537/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9435 - loss: 0.3566\n",
      "Epoch 537: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9435 - loss: 0.3565 - val_accuracy: 0.7240 - val_loss: 1.3463\n",
      "Epoch 538/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9483 - loss: 0.3377\n",
      "Epoch 538: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9482 - loss: 0.3379 - val_accuracy: 0.7000 - val_loss: 1.3573\n",
      "Epoch 539/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9352 - loss: 0.3764\n",
      "Epoch 539: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9352 - loss: 0.3765 - val_accuracy: 0.7320 - val_loss: 1.2681\n",
      "Epoch 540/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9458 - loss: 0.3616\n",
      "Epoch 540: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9458 - loss: 0.3617 - val_accuracy: 0.7360 - val_loss: 1.4098\n",
      "Epoch 541/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9373 - loss: 0.3952\n",
      "Epoch 541: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9374 - loss: 0.3948 - val_accuracy: 0.7160 - val_loss: 1.4277\n",
      "Epoch 542/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9536 - loss: 0.3462\n",
      "Epoch 542: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9536 - loss: 0.3464 - val_accuracy: 0.7360 - val_loss: 1.2280\n",
      "Epoch 543/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9399 - loss: 0.3794\n",
      "Epoch 543: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9400 - loss: 0.3792 - val_accuracy: 0.7360 - val_loss: 1.2487\n",
      "Epoch 544/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9547 - loss: 0.3443\n",
      "Epoch 544: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9547 - loss: 0.3444 - val_accuracy: 0.7440 - val_loss: 1.3031\n",
      "Epoch 545/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9436 - loss: 0.3660\n",
      "Epoch 545: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9437 - loss: 0.3660 - val_accuracy: 0.7360 - val_loss: 1.2536\n",
      "Epoch 546/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9538 - loss: 0.3387\n",
      "Epoch 546: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9537 - loss: 0.3393 - val_accuracy: 0.7240 - val_loss: 1.3187\n",
      "Epoch 547/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9305 - loss: 0.3943\n",
      "Epoch 547: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9311 - loss: 0.3939 - val_accuracy: 0.7200 - val_loss: 1.3505\n",
      "Epoch 548/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9534 - loss: 0.3481\n",
      "Epoch 548: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9528 - loss: 0.3492 - val_accuracy: 0.7280 - val_loss: 1.3565\n",
      "Epoch 549/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9411 - loss: 0.3686\n",
      "Epoch 549: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9410 - loss: 0.3694 - val_accuracy: 0.7360 - val_loss: 1.3420\n",
      "Epoch 550/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9562 - loss: 0.3552\n",
      "Epoch 550: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9562 - loss: 0.3550 - val_accuracy: 0.7160 - val_loss: 1.3318\n",
      "Epoch 551/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9553 - loss: 0.3417\n",
      "Epoch 551: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9549 - loss: 0.3427 - val_accuracy: 0.7120 - val_loss: 1.3332\n",
      "Epoch 552/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9447 - loss: 0.3662\n",
      "Epoch 552: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9450 - loss: 0.3654 - val_accuracy: 0.7320 - val_loss: 1.3042\n",
      "Epoch 553/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9461 - loss: 0.3543\n",
      "Epoch 553: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9461 - loss: 0.3545 - val_accuracy: 0.7240 - val_loss: 1.3872\n",
      "Epoch 554/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9433 - loss: 0.3592\n",
      "Epoch 554: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9432 - loss: 0.3596 - val_accuracy: 0.7200 - val_loss: 1.3071\n",
      "Epoch 555/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9476 - loss: 0.3533\n",
      "Epoch 555: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9471 - loss: 0.3541 - val_accuracy: 0.7280 - val_loss: 1.3455\n",
      "Epoch 556/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9446 - loss: 0.3600\n",
      "Epoch 556: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9448 - loss: 0.3600 - val_accuracy: 0.7240 - val_loss: 1.2892\n",
      "Epoch 557/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9627 - loss: 0.3554\n",
      "Epoch 557: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9623 - loss: 0.3558 - val_accuracy: 0.7160 - val_loss: 1.2842\n",
      "Epoch 558/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9392 - loss: 0.3732\n",
      "Epoch 558: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9391 - loss: 0.3733 - val_accuracy: 0.7240 - val_loss: 1.4401\n",
      "Epoch 559/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9463 - loss: 0.3480\n",
      "Epoch 559: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9463 - loss: 0.3480 - val_accuracy: 0.7160 - val_loss: 1.3581\n",
      "Epoch 560/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9591 - loss: 0.3271\n",
      "Epoch 560: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9588 - loss: 0.3279 - val_accuracy: 0.7480 - val_loss: 1.3032\n",
      "Epoch 561/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9515 - loss: 0.3620\n",
      "Epoch 561: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9513 - loss: 0.3623 - val_accuracy: 0.7360 - val_loss: 1.3269\n",
      "Epoch 562/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9522 - loss: 0.3476\n",
      "Epoch 562: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9522 - loss: 0.3477 - val_accuracy: 0.7080 - val_loss: 1.3423\n",
      "Epoch 563/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9505 - loss: 0.3428\n",
      "Epoch 563: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9506 - loss: 0.3428 - val_accuracy: 0.7120 - val_loss: 1.3058\n",
      "Epoch 564/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9523 - loss: 0.3561\n",
      "Epoch 564: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9522 - loss: 0.3562 - val_accuracy: 0.7080 - val_loss: 1.3529\n",
      "Epoch 565/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9510 - loss: 0.3669\n",
      "Epoch 565: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9508 - loss: 0.3672 - val_accuracy: 0.7200 - val_loss: 1.3512\n",
      "Epoch 566/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9507 - loss: 0.3583\n",
      "Epoch 566: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9506 - loss: 0.3584 - val_accuracy: 0.7200 - val_loss: 1.4225\n",
      "Epoch 567/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9531 - loss: 0.3620\n",
      "Epoch 567: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9531 - loss: 0.3615 - val_accuracy: 0.7280 - val_loss: 1.4000\n",
      "Epoch 568/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9494 - loss: 0.3474\n",
      "Epoch 568: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9495 - loss: 0.3472 - val_accuracy: 0.7120 - val_loss: 1.4092\n",
      "Epoch 569/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9551 - loss: 0.3456\n",
      "Epoch 569: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9547 - loss: 0.3460 - val_accuracy: 0.7280 - val_loss: 1.4083\n",
      "Epoch 570/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9602 - loss: 0.3288\n",
      "Epoch 570: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9600 - loss: 0.3292 - val_accuracy: 0.7120 - val_loss: 1.4278\n",
      "Epoch 571/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9458 - loss: 0.3534\n",
      "Epoch 571: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9458 - loss: 0.3535 - val_accuracy: 0.7200 - val_loss: 1.3848\n",
      "Epoch 572/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9424 - loss: 0.3728\n",
      "Epoch 572: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9424 - loss: 0.3726 - val_accuracy: 0.7200 - val_loss: 1.3000\n",
      "Epoch 573/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9450 - loss: 0.3546\n",
      "Epoch 573: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9450 - loss: 0.3546 - val_accuracy: 0.7120 - val_loss: 1.3502\n",
      "Epoch 574/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9380 - loss: 0.3797\n",
      "Epoch 574: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9381 - loss: 0.3796 - val_accuracy: 0.7240 - val_loss: 1.3940\n",
      "Epoch 575/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9437 - loss: 0.3833\n",
      "Epoch 575: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9439 - loss: 0.3824 - val_accuracy: 0.7280 - val_loss: 1.2913\n",
      "Epoch 576/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9466 - loss: 0.3621\n",
      "Epoch 576: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9466 - loss: 0.3622 - val_accuracy: 0.7520 - val_loss: 1.3478\n",
      "Epoch 577/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9422 - loss: 0.3780\n",
      "Epoch 577: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9423 - loss: 0.3780 - val_accuracy: 0.7240 - val_loss: 1.3059\n",
      "Epoch 578/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9493 - loss: 0.3672\n",
      "Epoch 578: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9491 - loss: 0.3668 - val_accuracy: 0.7400 - val_loss: 1.2878\n",
      "Epoch 579/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9563 - loss: 0.3422\n",
      "Epoch 579: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9561 - loss: 0.3425 - val_accuracy: 0.7360 - val_loss: 1.4228\n",
      "Epoch 580/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9545 - loss: 0.3441\n",
      "Epoch 580: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9545 - loss: 0.3441 - val_accuracy: 0.6960 - val_loss: 1.3622\n",
      "Epoch 581/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9428 - loss: 0.3640\n",
      "Epoch 581: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9428 - loss: 0.3642 - val_accuracy: 0.7200 - val_loss: 1.3083\n",
      "Epoch 582/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9526 - loss: 0.3303\n",
      "Epoch 582: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9525 - loss: 0.3307 - val_accuracy: 0.7320 - val_loss: 1.3251\n",
      "Epoch 583/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9451 - loss: 0.3631\n",
      "Epoch 583: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9452 - loss: 0.3628 - val_accuracy: 0.7240 - val_loss: 1.2456\n",
      "Epoch 584/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9480 - loss: 0.3369\n",
      "Epoch 584: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9478 - loss: 0.3378 - val_accuracy: 0.7320 - val_loss: 1.3717\n",
      "Epoch 585/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9461 - loss: 0.3539\n",
      "Epoch 585: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9460 - loss: 0.3541 - val_accuracy: 0.7320 - val_loss: 1.3150\n",
      "Epoch 586/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9434 - loss: 0.3551\n",
      "Epoch 586: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9433 - loss: 0.3553 - val_accuracy: 0.7200 - val_loss: 1.2208\n",
      "Epoch 587/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9533 - loss: 0.3330\n",
      "Epoch 587: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9532 - loss: 0.3333 - val_accuracy: 0.7280 - val_loss: 1.3543\n",
      "Epoch 588/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9413 - loss: 0.3675\n",
      "Epoch 588: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9412 - loss: 0.3676 - val_accuracy: 0.7120 - val_loss: 1.3432\n",
      "Epoch 589/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9474 - loss: 0.3483\n",
      "Epoch 589: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9472 - loss: 0.3491 - val_accuracy: 0.7280 - val_loss: 1.3323\n",
      "Epoch 590/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9440 - loss: 0.3665\n",
      "Epoch 590: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9441 - loss: 0.3663 - val_accuracy: 0.7320 - val_loss: 1.3307\n",
      "Epoch 591/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9315 - loss: 0.3758\n",
      "Epoch 591: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9317 - loss: 0.3754 - val_accuracy: 0.7120 - val_loss: 1.4499\n",
      "Epoch 592/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9416 - loss: 0.3719\n",
      "Epoch 592: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9417 - loss: 0.3716 - val_accuracy: 0.7600 - val_loss: 1.2488\n",
      "Epoch 593/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9429 - loss: 0.3709\n",
      "Epoch 593: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9428 - loss: 0.3716 - val_accuracy: 0.7160 - val_loss: 1.2724\n",
      "Epoch 594/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9479 - loss: 0.3573\n",
      "Epoch 594: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9479 - loss: 0.3575 - val_accuracy: 0.7200 - val_loss: 1.2872\n",
      "Epoch 595/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9420 - loss: 0.3608\n",
      "Epoch 595: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9420 - loss: 0.3609 - val_accuracy: 0.7200 - val_loss: 1.2940\n",
      "Epoch 596/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9483 - loss: 0.3611\n",
      "Epoch 596: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9482 - loss: 0.3611 - val_accuracy: 0.7120 - val_loss: 1.2471\n",
      "Epoch 597/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9451 - loss: 0.3722\n",
      "Epoch 597: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9451 - loss: 0.3719 - val_accuracy: 0.7360 - val_loss: 1.2120\n",
      "Epoch 598/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9398 - loss: 0.3723\n",
      "Epoch 598: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9401 - loss: 0.3716 - val_accuracy: 0.7320 - val_loss: 1.2182\n",
      "Epoch 599/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9542 - loss: 0.3368\n",
      "Epoch 599: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9540 - loss: 0.3371 - val_accuracy: 0.7360 - val_loss: 1.2486\n",
      "Epoch 600/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9518 - loss: 0.3485\n",
      "Epoch 600: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9516 - loss: 0.3490 - val_accuracy: 0.7400 - val_loss: 1.3333\n",
      "Epoch 601/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9392 - loss: 0.3685\n",
      "Epoch 601: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9392 - loss: 0.3685 - val_accuracy: 0.7160 - val_loss: 1.2659\n",
      "Epoch 602/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9366 - loss: 0.3615\n",
      "Epoch 602: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9366 - loss: 0.3619 - val_accuracy: 0.7160 - val_loss: 1.2902\n",
      "Epoch 603/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9616 - loss: 0.3196\n",
      "Epoch 603: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9613 - loss: 0.3205 - val_accuracy: 0.6920 - val_loss: 1.4567\n",
      "Epoch 604/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9476 - loss: 0.3361\n",
      "Epoch 604: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9476 - loss: 0.3362 - val_accuracy: 0.7000 - val_loss: 1.3385\n",
      "Epoch 605/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9460 - loss: 0.3440\n",
      "Epoch 605: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9461 - loss: 0.3440 - val_accuracy: 0.6960 - val_loss: 1.3093\n",
      "Epoch 606/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9531 - loss: 0.3369\n",
      "Epoch 606: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9529 - loss: 0.3374 - val_accuracy: 0.7200 - val_loss: 1.3208\n",
      "Epoch 607/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9519 - loss: 0.3269\n",
      "Epoch 607: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9521 - loss: 0.3268 - val_accuracy: 0.7400 - val_loss: 1.4069\n",
      "Epoch 608/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9513 - loss: 0.3359\n",
      "Epoch 608: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9513 - loss: 0.3359 - val_accuracy: 0.7400 - val_loss: 1.2215\n",
      "Epoch 609/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9522 - loss: 0.3319\n",
      "Epoch 609: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9522 - loss: 0.3320 - val_accuracy: 0.7120 - val_loss: 1.3025\n",
      "Epoch 610/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9387 - loss: 0.3733\n",
      "Epoch 610: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9393 - loss: 0.3712 - val_accuracy: 0.7360 - val_loss: 1.2854\n",
      "Epoch 611/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9521 - loss: 0.3441\n",
      "Epoch 611: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9521 - loss: 0.3437 - val_accuracy: 0.7200 - val_loss: 1.4625\n",
      "Epoch 612/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9449 - loss: 0.3355\n",
      "Epoch 612: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9450 - loss: 0.3353 - val_accuracy: 0.7280 - val_loss: 1.2472\n",
      "Epoch 613/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9543 - loss: 0.3255\n",
      "Epoch 613: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9540 - loss: 0.3260 - val_accuracy: 0.7040 - val_loss: 1.2958\n",
      "Epoch 614/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9561 - loss: 0.3268\n",
      "Epoch 614: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9562 - loss: 0.3259 - val_accuracy: 0.7160 - val_loss: 1.3037\n",
      "Epoch 615/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9418 - loss: 0.3580\n",
      "Epoch 615: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9419 - loss: 0.3579 - val_accuracy: 0.7040 - val_loss: 1.3500\n",
      "Epoch 616/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9622 - loss: 0.3173\n",
      "Epoch 616: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9621 - loss: 0.3173 - val_accuracy: 0.7120 - val_loss: 1.4065\n",
      "Epoch 617/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9482 - loss: 0.3262\n",
      "Epoch 617: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9481 - loss: 0.3266 - val_accuracy: 0.7160 - val_loss: 1.3561\n",
      "Epoch 618/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9526 - loss: 0.3155\n",
      "Epoch 618: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9524 - loss: 0.3164 - val_accuracy: 0.7160 - val_loss: 1.4102\n",
      "Epoch 619/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9441 - loss: 0.3529\n",
      "Epoch 619: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9441 - loss: 0.3534 - val_accuracy: 0.7080 - val_loss: 1.4255\n",
      "Epoch 620/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9548 - loss: 0.3374\n",
      "Epoch 620: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9546 - loss: 0.3377 - val_accuracy: 0.7640 - val_loss: 1.2907\n",
      "Epoch 621/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9560 - loss: 0.3376\n",
      "Epoch 621: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9559 - loss: 0.3383 - val_accuracy: 0.7200 - val_loss: 1.3884\n",
      "Epoch 622/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9562 - loss: 0.3428\n",
      "Epoch 622: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9559 - loss: 0.3431 - val_accuracy: 0.7240 - val_loss: 1.3656\n",
      "Epoch 623/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9252 - loss: 0.3839\n",
      "Epoch 623: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9256 - loss: 0.3833 - val_accuracy: 0.7240 - val_loss: 1.3842\n",
      "Epoch 624/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9508 - loss: 0.3390\n",
      "Epoch 624: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9505 - loss: 0.3398 - val_accuracy: 0.7400 - val_loss: 1.3640\n",
      "Epoch 625/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9512 - loss: 0.3486\n",
      "Epoch 625: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9512 - loss: 0.3487 - val_accuracy: 0.7280 - val_loss: 1.4060\n",
      "Epoch 626/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9579 - loss: 0.3225\n",
      "Epoch 626: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9578 - loss: 0.3225 - val_accuracy: 0.7360 - val_loss: 1.4006\n",
      "Epoch 627/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9454 - loss: 0.3458\n",
      "Epoch 627: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9454 - loss: 0.3457 - val_accuracy: 0.7400 - val_loss: 1.4050\n",
      "Epoch 628/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9464 - loss: 0.3621\n",
      "Epoch 628: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9463 - loss: 0.3621 - val_accuracy: 0.7120 - val_loss: 1.5345\n",
      "Epoch 629/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9477 - loss: 0.3465\n",
      "Epoch 629: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9478 - loss: 0.3463 - val_accuracy: 0.7400 - val_loss: 1.3176\n",
      "Epoch 630/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9567 - loss: 0.3304\n",
      "Epoch 630: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9563 - loss: 0.3315 - val_accuracy: 0.7360 - val_loss: 1.3903\n",
      "Epoch 631/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9433 - loss: 0.3501\n",
      "Epoch 631: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9432 - loss: 0.3506 - val_accuracy: 0.7320 - val_loss: 1.2679\n",
      "Epoch 632/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9525 - loss: 0.3517\n",
      "Epoch 632: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9523 - loss: 0.3517 - val_accuracy: 0.7080 - val_loss: 1.3801\n",
      "Epoch 633/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9582 - loss: 0.3239\n",
      "Epoch 633: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9580 - loss: 0.3243 - val_accuracy: 0.7040 - val_loss: 1.4198\n",
      "Epoch 634/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9502 - loss: 0.3560\n",
      "Epoch 634: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9501 - loss: 0.3560 - val_accuracy: 0.7240 - val_loss: 1.3957\n",
      "Epoch 635/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9390 - loss: 0.3921\n",
      "Epoch 635: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9390 - loss: 0.3917 - val_accuracy: 0.7200 - val_loss: 1.3718\n",
      "Epoch 636/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9535 - loss: 0.3615\n",
      "Epoch 636: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9537 - loss: 0.3611 - val_accuracy: 0.7200 - val_loss: 1.2455\n",
      "Epoch 637/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9584 - loss: 0.3232\n",
      "Epoch 637: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9584 - loss: 0.3236 - val_accuracy: 0.7000 - val_loss: 1.2663\n",
      "Epoch 638/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9496 - loss: 0.3425\n",
      "Epoch 638: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9494 - loss: 0.3431 - val_accuracy: 0.7040 - val_loss: 1.3890\n",
      "Epoch 639/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9575 - loss: 0.3252\n",
      "Epoch 639: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9574 - loss: 0.3253 - val_accuracy: 0.7360 - val_loss: 1.2465\n",
      "Epoch 640/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9570 - loss: 0.3253\n",
      "Epoch 640: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9571 - loss: 0.3254 - val_accuracy: 0.7280 - val_loss: 1.3362\n",
      "Epoch 641/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9444 - loss: 0.3579\n",
      "Epoch 641: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9443 - loss: 0.3588 - val_accuracy: 0.7080 - val_loss: 1.3434\n",
      "Epoch 642/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9504 - loss: 0.3448\n",
      "Epoch 642: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9504 - loss: 0.3450 - val_accuracy: 0.7200 - val_loss: 1.3277\n",
      "Epoch 643/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9542 - loss: 0.3455\n",
      "Epoch 643: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9542 - loss: 0.3455 - val_accuracy: 0.7040 - val_loss: 1.4383\n",
      "Epoch 644/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9500 - loss: 0.3544\n",
      "Epoch 644: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9500 - loss: 0.3543 - val_accuracy: 0.7080 - val_loss: 1.3374\n",
      "Epoch 645/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9452 - loss: 0.3425\n",
      "Epoch 645: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9453 - loss: 0.3429 - val_accuracy: 0.7280 - val_loss: 1.3545\n",
      "Epoch 646/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9611 - loss: 0.3203\n",
      "Epoch 646: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9611 - loss: 0.3206 - val_accuracy: 0.7160 - val_loss: 1.3536\n",
      "Epoch 647/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9359 - loss: 0.3587\n",
      "Epoch 647: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9360 - loss: 0.3592 - val_accuracy: 0.6960 - val_loss: 1.3905\n",
      "Epoch 648/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9462 - loss: 0.3465\n",
      "Epoch 648: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9461 - loss: 0.3469 - val_accuracy: 0.7280 - val_loss: 1.4395\n",
      "Epoch 649/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9609 - loss: 0.3197\n",
      "Epoch 649: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9608 - loss: 0.3200 - val_accuracy: 0.7240 - val_loss: 1.3213\n",
      "Epoch 650/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9488 - loss: 0.3683\n",
      "Epoch 650: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9489 - loss: 0.3677 - val_accuracy: 0.7400 - val_loss: 1.2506\n",
      "Epoch 651/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9529 - loss: 0.3411\n",
      "Epoch 651: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9530 - loss: 0.3405 - val_accuracy: 0.7360 - val_loss: 1.2151\n",
      "Epoch 652/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9504 - loss: 0.3287\n",
      "Epoch 652: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9504 - loss: 0.3290 - val_accuracy: 0.7440 - val_loss: 1.3049\n",
      "Epoch 653/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9541 - loss: 0.3245\n",
      "Epoch 653: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9542 - loss: 0.3244 - val_accuracy: 0.7280 - val_loss: 1.3036\n",
      "Epoch 654/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9417 - loss: 0.3448\n",
      "Epoch 654: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9419 - loss: 0.3446 - val_accuracy: 0.7480 - val_loss: 1.2220\n",
      "Epoch 655/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9573 - loss: 0.3206\n",
      "Epoch 655: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9572 - loss: 0.3208 - val_accuracy: 0.7080 - val_loss: 1.3885\n",
      "Epoch 656/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9548 - loss: 0.3269\n",
      "Epoch 656: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9547 - loss: 0.3269 - val_accuracy: 0.7440 - val_loss: 1.2254\n",
      "Epoch 657/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9473 - loss: 0.3549\n",
      "Epoch 657: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9474 - loss: 0.3547 - val_accuracy: 0.7280 - val_loss: 1.1932\n",
      "Epoch 658/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9473 - loss: 0.3383\n",
      "Epoch 658: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9473 - loss: 0.3384 - val_accuracy: 0.7280 - val_loss: 1.2936\n",
      "Epoch 659/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9479 - loss: 0.3443\n",
      "Epoch 659: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9479 - loss: 0.3439 - val_accuracy: 0.7040 - val_loss: 1.3381\n",
      "Epoch 660/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9482 - loss: 0.3289\n",
      "Epoch 660: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9482 - loss: 0.3289 - val_accuracy: 0.7200 - val_loss: 1.2529\n",
      "Epoch 661/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9524 - loss: 0.3278\n",
      "Epoch 661: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9520 - loss: 0.3291 - val_accuracy: 0.7080 - val_loss: 1.3338\n",
      "Epoch 662/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9489 - loss: 0.3286\n",
      "Epoch 662: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9485 - loss: 0.3298 - val_accuracy: 0.7240 - val_loss: 1.3211\n",
      "Epoch 663/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9441 - loss: 0.3688\n",
      "Epoch 663: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9441 - loss: 0.3691 - val_accuracy: 0.7320 - val_loss: 1.3504\n",
      "Epoch 664/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9485 - loss: 0.3495\n",
      "Epoch 664: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9485 - loss: 0.3495 - val_accuracy: 0.7200 - val_loss: 1.3822\n",
      "Epoch 665/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9537 - loss: 0.3361\n",
      "Epoch 665: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9536 - loss: 0.3364 - val_accuracy: 0.7280 - val_loss: 1.3566\n",
      "Epoch 666/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9619 - loss: 0.3154\n",
      "Epoch 666: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9618 - loss: 0.3158 - val_accuracy: 0.7280 - val_loss: 1.2631\n",
      "Epoch 667/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9503 - loss: 0.3261\n",
      "Epoch 667: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9503 - loss: 0.3260 - val_accuracy: 0.7200 - val_loss: 1.3317\n",
      "Epoch 668/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9518 - loss: 0.3312\n",
      "Epoch 668: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9517 - loss: 0.3313 - val_accuracy: 0.7240 - val_loss: 1.3899\n",
      "Epoch 669/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9467 - loss: 0.3433\n",
      "Epoch 669: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9468 - loss: 0.3435 - val_accuracy: 0.7160 - val_loss: 1.3251\n",
      "Epoch 670/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9464 - loss: 0.3427\n",
      "Epoch 670: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9464 - loss: 0.3427 - val_accuracy: 0.7080 - val_loss: 1.4169\n",
      "Epoch 671/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9574 - loss: 0.3240\n",
      "Epoch 671: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9572 - loss: 0.3243 - val_accuracy: 0.7080 - val_loss: 1.6163\n",
      "Epoch 672/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9593 - loss: 0.3307\n",
      "Epoch 672: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9591 - loss: 0.3306 - val_accuracy: 0.7320 - val_loss: 1.3384\n",
      "Epoch 673/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9523 - loss: 0.3047\n",
      "Epoch 673: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9522 - loss: 0.3049 - val_accuracy: 0.7240 - val_loss: 1.3121\n",
      "Epoch 674/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9413 - loss: 0.3469\n",
      "Epoch 674: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9413 - loss: 0.3473 - val_accuracy: 0.7320 - val_loss: 1.3649\n",
      "Epoch 675/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9335 - loss: 0.3693\n",
      "Epoch 675: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9336 - loss: 0.3691 - val_accuracy: 0.7120 - val_loss: 1.3138\n",
      "Epoch 676/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9570 - loss: 0.3281\n",
      "Epoch 676: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9570 - loss: 0.3282 - val_accuracy: 0.7240 - val_loss: 1.3338\n",
      "Epoch 677/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9516 - loss: 0.3259\n",
      "Epoch 677: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9516 - loss: 0.3262 - val_accuracy: 0.7240 - val_loss: 1.4364\n",
      "Epoch 678/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9479 - loss: 0.3505\n",
      "Epoch 678: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9478 - loss: 0.3507 - val_accuracy: 0.7200 - val_loss: 1.3064\n",
      "Epoch 679/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9512 - loss: 0.3363\n",
      "Epoch 679: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9510 - loss: 0.3373 - val_accuracy: 0.7200 - val_loss: 1.3534\n",
      "Epoch 680/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9602 - loss: 0.3275\n",
      "Epoch 680: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9600 - loss: 0.3278 - val_accuracy: 0.7320 - val_loss: 1.3289\n",
      "Epoch 681/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9491 - loss: 0.3396\n",
      "Epoch 681: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9490 - loss: 0.3398 - val_accuracy: 0.7240 - val_loss: 1.3813\n",
      "Epoch 682/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9373 - loss: 0.3666\n",
      "Epoch 682: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9375 - loss: 0.3661 - val_accuracy: 0.7280 - val_loss: 1.5091\n",
      "Epoch 683/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9536 - loss: 0.3394\n",
      "Epoch 683: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9536 - loss: 0.3395 - val_accuracy: 0.7320 - val_loss: 1.2712\n",
      "Epoch 684/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9656 - loss: 0.3068\n",
      "Epoch 684: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9654 - loss: 0.3075 - val_accuracy: 0.7240 - val_loss: 1.2443\n",
      "Epoch 685/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9552 - loss: 0.3303\n",
      "Epoch 685: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9552 - loss: 0.3302 - val_accuracy: 0.7400 - val_loss: 1.3038\n",
      "Epoch 686/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9538 - loss: 0.3228\n",
      "Epoch 686: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9538 - loss: 0.3230 - val_accuracy: 0.7280 - val_loss: 1.4066\n",
      "Epoch 687/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9614 - loss: 0.3088\n",
      "Epoch 687: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9613 - loss: 0.3093 - val_accuracy: 0.7320 - val_loss: 1.2761\n",
      "Epoch 688/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9559 - loss: 0.3231\n",
      "Epoch 688: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9560 - loss: 0.3229 - val_accuracy: 0.7360 - val_loss: 1.2923\n",
      "Epoch 689/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9641 - loss: 0.2956\n",
      "Epoch 689: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9641 - loss: 0.2956 - val_accuracy: 0.7280 - val_loss: 1.3336\n",
      "Epoch 690/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9631 - loss: 0.2806\n",
      "Epoch 690: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9631 - loss: 0.2808 - val_accuracy: 0.7280 - val_loss: 1.3946\n",
      "Epoch 691/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9639 - loss: 0.2944\n",
      "Epoch 691: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9638 - loss: 0.2948 - val_accuracy: 0.7160 - val_loss: 1.2913\n",
      "Epoch 692/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9468 - loss: 0.3362\n",
      "Epoch 692: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9465 - loss: 0.3369 - val_accuracy: 0.7440 - val_loss: 1.3363\n",
      "Epoch 693/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9465 - loss: 0.3448\n",
      "Epoch 693: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9464 - loss: 0.3451 - val_accuracy: 0.7320 - val_loss: 1.3951\n",
      "Epoch 694/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9623 - loss: 0.3064\n",
      "Epoch 694: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9623 - loss: 0.3066 - val_accuracy: 0.7440 - val_loss: 1.3119\n",
      "Epoch 695/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9535 - loss: 0.3219\n",
      "Epoch 695: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9534 - loss: 0.3222 - val_accuracy: 0.7280 - val_loss: 1.4191\n",
      "Epoch 696/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9490 - loss: 0.3293\n",
      "Epoch 696: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9493 - loss: 0.3288 - val_accuracy: 0.7160 - val_loss: 1.3581\n",
      "Epoch 697/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9618 - loss: 0.2922\n",
      "Epoch 697: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9615 - loss: 0.2930 - val_accuracy: 0.7120 - val_loss: 1.4409\n",
      "Epoch 698/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9465 - loss: 0.3296\n",
      "Epoch 698: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9465 - loss: 0.3299 - val_accuracy: 0.7120 - val_loss: 1.4231\n",
      "Epoch 699/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9437 - loss: 0.3376\n",
      "Epoch 699: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9437 - loss: 0.3375 - val_accuracy: 0.7560 - val_loss: 1.3000\n",
      "Epoch 700/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9434 - loss: 0.3384\n",
      "Epoch 700: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9432 - loss: 0.3392 - val_accuracy: 0.7320 - val_loss: 1.3097\n",
      "Epoch 701/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9476 - loss: 0.3406\n",
      "Epoch 701: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9477 - loss: 0.3403 - val_accuracy: 0.7400 - val_loss: 1.3863\n",
      "Epoch 702/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9482 - loss: 0.3297\n",
      "Epoch 702: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9483 - loss: 0.3297 - val_accuracy: 0.7440 - val_loss: 1.3233\n",
      "Epoch 703/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9511 - loss: 0.3453\n",
      "Epoch 703: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9509 - loss: 0.3453 - val_accuracy: 0.7440 - val_loss: 1.2757\n",
      "Epoch 704/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9541 - loss: 0.3356\n",
      "Epoch 704: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.9541 - loss: 0.3355 - val_accuracy: 0.7480 - val_loss: 1.2772\n",
      "Epoch 705/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9469 - loss: 0.3455\n",
      "Epoch 705: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9469 - loss: 0.3451 - val_accuracy: 0.7240 - val_loss: 1.3482\n",
      "Epoch 706/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9567 - loss: 0.3179\n",
      "Epoch 706: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9567 - loss: 0.3179 - val_accuracy: 0.7200 - val_loss: 1.2484\n",
      "Epoch 707/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9543 - loss: 0.3245\n",
      "Epoch 707: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9542 - loss: 0.3247 - val_accuracy: 0.7320 - val_loss: 1.1930\n",
      "Epoch 708/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9406 - loss: 0.3636\n",
      "Epoch 708: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9407 - loss: 0.3634 - val_accuracy: 0.7280 - val_loss: 1.3812\n",
      "Epoch 709/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9482 - loss: 0.3287\n",
      "Epoch 709: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9483 - loss: 0.3287 - val_accuracy: 0.7280 - val_loss: 1.2833\n",
      "Epoch 710/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9505 - loss: 0.3457\n",
      "Epoch 710: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9506 - loss: 0.3455 - val_accuracy: 0.7280 - val_loss: 1.2616\n",
      "Epoch 711/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9571 - loss: 0.3257\n",
      "Epoch 711: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9570 - loss: 0.3257 - val_accuracy: 0.7440 - val_loss: 1.2030\n",
      "Epoch 712/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9553 - loss: 0.3166\n",
      "Epoch 712: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9553 - loss: 0.3164 - val_accuracy: 0.7360 - val_loss: 1.3817\n",
      "Epoch 713/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9531 - loss: 0.3343\n",
      "Epoch 713: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9529 - loss: 0.3344 - val_accuracy: 0.7520 - val_loss: 1.2447\n",
      "Epoch 714/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9481 - loss: 0.3241\n",
      "Epoch 714: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9483 - loss: 0.3240 - val_accuracy: 0.7200 - val_loss: 1.2480\n",
      "Epoch 715/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9575 - loss: 0.3108\n",
      "Epoch 715: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9574 - loss: 0.3109 - val_accuracy: 0.7240 - val_loss: 1.2764\n",
      "Epoch 716/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9568 - loss: 0.3118\n",
      "Epoch 716: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9567 - loss: 0.3122 - val_accuracy: 0.7280 - val_loss: 1.3941\n",
      "Epoch 717/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9456 - loss: 0.3319\n",
      "Epoch 717: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9456 - loss: 0.3318 - val_accuracy: 0.7480 - val_loss: 1.4232\n",
      "Epoch 718/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9545 - loss: 0.3296\n",
      "Epoch 718: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9545 - loss: 0.3298 - val_accuracy: 0.7320 - val_loss: 1.3542\n",
      "Epoch 719/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9411 - loss: 0.3546\n",
      "Epoch 719: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9412 - loss: 0.3546 - val_accuracy: 0.7440 - val_loss: 1.3042\n",
      "Epoch 720/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9480 - loss: 0.3481\n",
      "Epoch 720: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9478 - loss: 0.3481 - val_accuracy: 0.7280 - val_loss: 1.3140\n",
      "Epoch 721/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9566 - loss: 0.3229\n",
      "Epoch 721: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9566 - loss: 0.3231 - val_accuracy: 0.7480 - val_loss: 1.2688\n",
      "Epoch 722/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9548 - loss: 0.3179\n",
      "Epoch 722: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9547 - loss: 0.3179 - val_accuracy: 0.7320 - val_loss: 1.2922\n",
      "Epoch 723/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9541 - loss: 0.3413\n",
      "Epoch 723: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9541 - loss: 0.3412 - val_accuracy: 0.7240 - val_loss: 1.3419\n",
      "Epoch 724/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9525 - loss: 0.3336\n",
      "Epoch 724: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9522 - loss: 0.3339 - val_accuracy: 0.7360 - val_loss: 1.2228\n",
      "Epoch 725/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9555 - loss: 0.3102\n",
      "Epoch 725: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9555 - loss: 0.3103 - val_accuracy: 0.7320 - val_loss: 1.2991\n",
      "Epoch 726/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9545 - loss: 0.3296\n",
      "Epoch 726: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9545 - loss: 0.3296 - val_accuracy: 0.7240 - val_loss: 1.3825\n",
      "Epoch 727/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9490 - loss: 0.3523\n",
      "Epoch 727: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9489 - loss: 0.3525 - val_accuracy: 0.7520 - val_loss: 1.2198\n",
      "Epoch 728/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9442 - loss: 0.3589\n",
      "Epoch 728: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9443 - loss: 0.3588 - val_accuracy: 0.7480 - val_loss: 1.2682\n",
      "Epoch 729/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9489 - loss: 0.3290\n",
      "Epoch 729: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9490 - loss: 0.3291 - val_accuracy: 0.7320 - val_loss: 1.2252\n",
      "Epoch 730/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9468 - loss: 0.3299\n",
      "Epoch 730: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9468 - loss: 0.3299 - val_accuracy: 0.7320 - val_loss: 1.2845\n",
      "Epoch 731/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9523 - loss: 0.3251\n",
      "Epoch 731: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9522 - loss: 0.3254 - val_accuracy: 0.7360 - val_loss: 1.3153\n",
      "Epoch 732/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9569 - loss: 0.3184\n",
      "Epoch 732: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9569 - loss: 0.3185 - val_accuracy: 0.7320 - val_loss: 1.3185\n",
      "Epoch 733/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9508 - loss: 0.3197\n",
      "Epoch 733: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9506 - loss: 0.3202 - val_accuracy: 0.7440 - val_loss: 1.3191\n",
      "Epoch 734/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9369 - loss: 0.3577\n",
      "Epoch 734: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9371 - loss: 0.3574 - val_accuracy: 0.7400 - val_loss: 1.2945\n",
      "Epoch 735/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9420 - loss: 0.3664\n",
      "Epoch 735: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9421 - loss: 0.3661 - val_accuracy: 0.7480 - val_loss: 1.3332\n",
      "Epoch 736/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9480 - loss: 0.3393\n",
      "Epoch 736: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9481 - loss: 0.3392 - val_accuracy: 0.7440 - val_loss: 1.2361\n",
      "Epoch 737/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9580 - loss: 0.3058\n",
      "Epoch 737: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9580 - loss: 0.3058 - val_accuracy: 0.7200 - val_loss: 1.3163\n",
      "Epoch 738/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9600 - loss: 0.3047\n",
      "Epoch 738: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9600 - loss: 0.3046 - val_accuracy: 0.7400 - val_loss: 1.3626\n",
      "Epoch 739/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9417 - loss: 0.3573\n",
      "Epoch 739: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9423 - loss: 0.3556 - val_accuracy: 0.7080 - val_loss: 1.3513\n",
      "Epoch 740/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9596 - loss: 0.3124\n",
      "Epoch 740: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9596 - loss: 0.3121 - val_accuracy: 0.7120 - val_loss: 1.3247\n",
      "Epoch 741/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9445 - loss: 0.3194\n",
      "Epoch 741: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9446 - loss: 0.3195 - val_accuracy: 0.7360 - val_loss: 1.2674\n",
      "Epoch 742/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9587 - loss: 0.3041\n",
      "Epoch 742: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9584 - loss: 0.3050 - val_accuracy: 0.7360 - val_loss: 1.2497\n",
      "Epoch 743/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9545 - loss: 0.3130\n",
      "Epoch 743: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9545 - loss: 0.3132 - val_accuracy: 0.7200 - val_loss: 1.2698\n",
      "Epoch 744/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9568 - loss: 0.2970\n",
      "Epoch 744: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9567 - loss: 0.2975 - val_accuracy: 0.7360 - val_loss: 1.3028\n",
      "Epoch 745/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9583 - loss: 0.2983\n",
      "Epoch 745: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9582 - loss: 0.2986 - val_accuracy: 0.7360 - val_loss: 1.2513\n",
      "Epoch 746/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9632 - loss: 0.2989\n",
      "Epoch 746: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9630 - loss: 0.2993 - val_accuracy: 0.7240 - val_loss: 1.1801\n",
      "Epoch 747/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9546 - loss: 0.3044\n",
      "Epoch 747: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9546 - loss: 0.3045 - val_accuracy: 0.7280 - val_loss: 1.3030\n",
      "Epoch 748/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9440 - loss: 0.3305\n",
      "Epoch 748: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9440 - loss: 0.3305 - val_accuracy: 0.7280 - val_loss: 1.2643\n",
      "Epoch 749/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9500 - loss: 0.3230\n",
      "Epoch 749: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9499 - loss: 0.3230 - val_accuracy: 0.7320 - val_loss: 1.2602\n",
      "Epoch 750/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9543 - loss: 0.3052\n",
      "Epoch 750: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9543 - loss: 0.3056 - val_accuracy: 0.7280 - val_loss: 1.3353\n",
      "Epoch 751/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9563 - loss: 0.3236\n",
      "Epoch 751: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9563 - loss: 0.3239 - val_accuracy: 0.7400 - val_loss: 1.3749\n",
      "Epoch 752/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9547 - loss: 0.3148\n",
      "Epoch 752: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9547 - loss: 0.3151 - val_accuracy: 0.7240 - val_loss: 1.2947\n",
      "Epoch 753/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9485 - loss: 0.3574\n",
      "Epoch 753: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9486 - loss: 0.3571 - val_accuracy: 0.7440 - val_loss: 1.3244\n",
      "Epoch 754/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9485 - loss: 0.3288\n",
      "Epoch 754: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9484 - loss: 0.3293 - val_accuracy: 0.7240 - val_loss: 1.3131\n",
      "Epoch 755/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9428 - loss: 0.3504\n",
      "Epoch 755: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9429 - loss: 0.3501 - val_accuracy: 0.7440 - val_loss: 1.2350\n",
      "Epoch 756/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9598 - loss: 0.3190\n",
      "Epoch 756: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9597 - loss: 0.3194 - val_accuracy: 0.7080 - val_loss: 1.2740\n",
      "Epoch 757/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9490 - loss: 0.3200\n",
      "Epoch 757: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9493 - loss: 0.3199 - val_accuracy: 0.7320 - val_loss: 1.4040\n",
      "Epoch 758/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9547 - loss: 0.3076\n",
      "Epoch 758: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9546 - loss: 0.3080 - val_accuracy: 0.7200 - val_loss: 1.3233\n",
      "Epoch 759/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9473 - loss: 0.3302\n",
      "Epoch 759: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9473 - loss: 0.3301 - val_accuracy: 0.7440 - val_loss: 1.2969\n",
      "Epoch 760/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9382 - loss: 0.3526\n",
      "Epoch 760: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9383 - loss: 0.3525 - val_accuracy: 0.7520 - val_loss: 1.2720\n",
      "Epoch 761/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9642 - loss: 0.3041\n",
      "Epoch 761: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9640 - loss: 0.3046 - val_accuracy: 0.7240 - val_loss: 1.2984\n",
      "Epoch 762/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9502 - loss: 0.3338\n",
      "Epoch 762: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9502 - loss: 0.3337 - val_accuracy: 0.7280 - val_loss: 1.2808\n",
      "Epoch 763/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9637 - loss: 0.2905\n",
      "Epoch 763: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9633 - loss: 0.2912 - val_accuracy: 0.7400 - val_loss: 1.2863\n",
      "Epoch 764/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9624 - loss: 0.2941\n",
      "Epoch 764: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9621 - loss: 0.2949 - val_accuracy: 0.7080 - val_loss: 1.3471\n",
      "Epoch 765/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9484 - loss: 0.3231\n",
      "Epoch 765: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9484 - loss: 0.3235 - val_accuracy: 0.7080 - val_loss: 1.3208\n",
      "Epoch 766/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9523 - loss: 0.3428\n",
      "Epoch 766: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9524 - loss: 0.3421 - val_accuracy: 0.7560 - val_loss: 1.1906\n",
      "Epoch 767/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9695 - loss: 0.2927\n",
      "Epoch 767: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9693 - loss: 0.2932 - val_accuracy: 0.7040 - val_loss: 1.3330\n",
      "Epoch 768/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9526 - loss: 0.3159\n",
      "Epoch 768: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9522 - loss: 0.3169 - val_accuracy: 0.7480 - val_loss: 1.2379\n",
      "Epoch 769/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9636 - loss: 0.3052\n",
      "Epoch 769: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9634 - loss: 0.3065 - val_accuracy: 0.7360 - val_loss: 1.3215\n",
      "Epoch 770/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9367 - loss: 0.3983\n",
      "Epoch 770: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9371 - loss: 0.3972 - val_accuracy: 0.7360 - val_loss: 1.2605\n",
      "Epoch 771/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9471 - loss: 0.3582\n",
      "Epoch 771: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9469 - loss: 0.3589 - val_accuracy: 0.7080 - val_loss: 1.3976\n",
      "Epoch 772/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9636 - loss: 0.3195\n",
      "Epoch 772: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9633 - loss: 0.3201 - val_accuracy: 0.7120 - val_loss: 1.2810\n",
      "Epoch 773/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9433 - loss: 0.3556\n",
      "Epoch 773: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9433 - loss: 0.3554 - val_accuracy: 0.7200 - val_loss: 1.3222\n",
      "Epoch 774/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9563 - loss: 0.3106\n",
      "Epoch 774: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9566 - loss: 0.3104 - val_accuracy: 0.7080 - val_loss: 1.3651\n",
      "Epoch 775/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9519 - loss: 0.3196\n",
      "Epoch 775: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9518 - loss: 0.3201 - val_accuracy: 0.7160 - val_loss: 1.4118\n",
      "Epoch 776/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9562 - loss: 0.3218\n",
      "Epoch 776: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9560 - loss: 0.3225 - val_accuracy: 0.7240 - val_loss: 1.2595\n",
      "Epoch 777/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9534 - loss: 0.3345\n",
      "Epoch 777: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9530 - loss: 0.3350 - val_accuracy: 0.7120 - val_loss: 1.2108\n",
      "Epoch 778/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9586 - loss: 0.3096\n",
      "Epoch 778: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9583 - loss: 0.3102 - val_accuracy: 0.7160 - val_loss: 1.3031\n",
      "Epoch 779/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9547 - loss: 0.3319\n",
      "Epoch 779: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9547 - loss: 0.3322 - val_accuracy: 0.7240 - val_loss: 1.3166\n",
      "Epoch 780/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9397 - loss: 0.3707\n",
      "Epoch 780: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9399 - loss: 0.3700 - val_accuracy: 0.7240 - val_loss: 1.3305\n",
      "Epoch 781/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9464 - loss: 0.3335\n",
      "Epoch 781: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9468 - loss: 0.3332 - val_accuracy: 0.7240 - val_loss: 1.3940\n",
      "Epoch 782/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9601 - loss: 0.3136\n",
      "Epoch 782: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9601 - loss: 0.3137 - val_accuracy: 0.7280 - val_loss: 1.2919\n",
      "Epoch 783/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9546 - loss: 0.3117\n",
      "Epoch 783: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9547 - loss: 0.3118 - val_accuracy: 0.7400 - val_loss: 1.3996\n",
      "Epoch 784/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9481 - loss: 0.3517\n",
      "Epoch 784: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9483 - loss: 0.3511 - val_accuracy: 0.7080 - val_loss: 1.3317\n",
      "Epoch 785/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9553 - loss: 0.3169\n",
      "Epoch 785: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9553 - loss: 0.3172 - val_accuracy: 0.7400 - val_loss: 1.2495\n",
      "Epoch 786/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9559 - loss: 0.3161\n",
      "Epoch 786: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9558 - loss: 0.3162 - val_accuracy: 0.7280 - val_loss: 1.2384\n",
      "Epoch 787/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9603 - loss: 0.3078\n",
      "Epoch 787: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9602 - loss: 0.3081 - val_accuracy: 0.7400 - val_loss: 1.3252\n",
      "Epoch 788/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9560 - loss: 0.3280\n",
      "Epoch 788: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9561 - loss: 0.3276 - val_accuracy: 0.7280 - val_loss: 1.2764\n",
      "Epoch 789/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9525 - loss: 0.3175\n",
      "Epoch 789: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9523 - loss: 0.3179 - val_accuracy: 0.7400 - val_loss: 1.3113\n",
      "Epoch 790/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9609 - loss: 0.2972\n",
      "Epoch 790: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9608 - loss: 0.2974 - val_accuracy: 0.7560 - val_loss: 1.2873\n",
      "Epoch 791/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9513 - loss: 0.3219\n",
      "Epoch 791: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9512 - loss: 0.3224 - val_accuracy: 0.7360 - val_loss: 1.3288\n",
      "Epoch 792/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9616 - loss: 0.2995\n",
      "Epoch 792: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9613 - loss: 0.3001 - val_accuracy: 0.7320 - val_loss: 1.3090\n",
      "Epoch 793/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9525 - loss: 0.3297\n",
      "Epoch 793: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9525 - loss: 0.3294 - val_accuracy: 0.7200 - val_loss: 1.2926\n",
      "Epoch 794/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9525 - loss: 0.3222\n",
      "Epoch 794: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9527 - loss: 0.3217 - val_accuracy: 0.7360 - val_loss: 1.3995\n",
      "Epoch 795/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9518 - loss: 0.3225\n",
      "Epoch 795: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9518 - loss: 0.3227 - val_accuracy: 0.6920 - val_loss: 1.4250\n",
      "Epoch 796/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9492 - loss: 0.3196\n",
      "Epoch 796: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9491 - loss: 0.3203 - val_accuracy: 0.7400 - val_loss: 1.4325\n",
      "Epoch 797/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9513 - loss: 0.3240\n",
      "Epoch 797: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9512 - loss: 0.3241 - val_accuracy: 0.7120 - val_loss: 1.3657\n",
      "Epoch 798/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9558 - loss: 0.3114\n",
      "Epoch 798: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9558 - loss: 0.3115 - val_accuracy: 0.7240 - val_loss: 1.4205\n",
      "Epoch 799/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9490 - loss: 0.3333\n",
      "Epoch 799: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9490 - loss: 0.3335 - val_accuracy: 0.7080 - val_loss: 1.3549\n",
      "Epoch 800/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9537 - loss: 0.3103\n",
      "Epoch 800: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9536 - loss: 0.3109 - val_accuracy: 0.7240 - val_loss: 1.3627\n",
      "Epoch 801/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9469 - loss: 0.3267\n",
      "Epoch 801: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9467 - loss: 0.3274 - val_accuracy: 0.7280 - val_loss: 1.3008\n",
      "Epoch 802/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9469 - loss: 0.3328\n",
      "Epoch 802: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9469 - loss: 0.3328 - val_accuracy: 0.7160 - val_loss: 1.4692\n",
      "Epoch 803/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9538 - loss: 0.3157\n",
      "Epoch 803: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9538 - loss: 0.3158 - val_accuracy: 0.7200 - val_loss: 1.3768\n",
      "Epoch 804/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9423 - loss: 0.3347\n",
      "Epoch 804: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9425 - loss: 0.3346 - val_accuracy: 0.7240 - val_loss: 1.3819\n",
      "Epoch 805/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9702 - loss: 0.2737\n",
      "Epoch 805: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9701 - loss: 0.2743 - val_accuracy: 0.7400 - val_loss: 1.2962\n",
      "Epoch 806/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9576 - loss: 0.2934\n",
      "Epoch 806: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9575 - loss: 0.2939 - val_accuracy: 0.7160 - val_loss: 1.4056\n",
      "Epoch 807/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9579 - loss: 0.3056\n",
      "Epoch 807: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9579 - loss: 0.3058 - val_accuracy: 0.7520 - val_loss: 1.2589\n",
      "Epoch 808/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9571 - loss: 0.3037\n",
      "Epoch 808: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9570 - loss: 0.3042 - val_accuracy: 0.7240 - val_loss: 1.3802\n",
      "Epoch 809/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9554 - loss: 0.3196\n",
      "Epoch 809: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9553 - loss: 0.3199 - val_accuracy: 0.7280 - val_loss: 1.4139\n",
      "Epoch 810/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9422 - loss: 0.3409\n",
      "Epoch 810: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9425 - loss: 0.3402 - val_accuracy: 0.7320 - val_loss: 1.3108\n",
      "Epoch 811/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9454 - loss: 0.3593\n",
      "Epoch 811: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9455 - loss: 0.3586 - val_accuracy: 0.7160 - val_loss: 1.3089\n",
      "Epoch 812/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9539 - loss: 0.3415\n",
      "Epoch 812: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9538 - loss: 0.3418 - val_accuracy: 0.7240 - val_loss: 1.3049\n",
      "Epoch 813/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9552 - loss: 0.3239\n",
      "Epoch 813: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9553 - loss: 0.3239 - val_accuracy: 0.7280 - val_loss: 1.3002\n",
      "Epoch 814/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9563 - loss: 0.3070\n",
      "Epoch 814: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9563 - loss: 0.3071 - val_accuracy: 0.7440 - val_loss: 1.3030\n",
      "Epoch 815/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9599 - loss: 0.3028\n",
      "Epoch 815: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9600 - loss: 0.3027 - val_accuracy: 0.7280 - val_loss: 1.3224\n",
      "Epoch 816/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9605 - loss: 0.2908\n",
      "Epoch 816: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9605 - loss: 0.2909 - val_accuracy: 0.7320 - val_loss: 1.3169\n",
      "Epoch 817/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9691 - loss: 0.2902\n",
      "Epoch 817: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9690 - loss: 0.2905 - val_accuracy: 0.7240 - val_loss: 1.2909\n",
      "Epoch 818/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9536 - loss: 0.2977\n",
      "Epoch 818: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.9536 - loss: 0.2977 - val_accuracy: 0.7280 - val_loss: 1.2972\n",
      "Epoch 819/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9506 - loss: 0.3132\n",
      "Epoch 819: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.9508 - loss: 0.3128 - val_accuracy: 0.7160 - val_loss: 1.4285\n",
      "Epoch 820/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9599 - loss: 0.2923\n",
      "Epoch 820: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9599 - loss: 0.2927 - val_accuracy: 0.7480 - val_loss: 1.3797\n",
      "Epoch 821/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9588 - loss: 0.2953\n",
      "Epoch 821: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9587 - loss: 0.2955 - val_accuracy: 0.7360 - val_loss: 1.3096\n",
      "Epoch 822/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9536 - loss: 0.3041\n",
      "Epoch 822: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9533 - loss: 0.3049 - val_accuracy: 0.6960 - val_loss: 1.3805\n",
      "Epoch 823/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9653 - loss: 0.2910\n",
      "Epoch 823: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9652 - loss: 0.2914 - val_accuracy: 0.7000 - val_loss: 1.3761\n",
      "Epoch 824/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9476 - loss: 0.3301\n",
      "Epoch 824: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9478 - loss: 0.3299 - val_accuracy: 0.7080 - val_loss: 1.4546\n",
      "Epoch 825/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9494 - loss: 0.3565\n",
      "Epoch 825: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9493 - loss: 0.3563 - val_accuracy: 0.7240 - val_loss: 1.4292\n",
      "Epoch 826/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9621 - loss: 0.2994\n",
      "Epoch 826: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9619 - loss: 0.2999 - val_accuracy: 0.7280 - val_loss: 1.4642\n",
      "Epoch 827/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9482 - loss: 0.3392\n",
      "Epoch 827: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9483 - loss: 0.3391 - val_accuracy: 0.7360 - val_loss: 1.3838\n",
      "Epoch 828/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9467 - loss: 0.3343\n",
      "Epoch 828: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9467 - loss: 0.3343 - val_accuracy: 0.7200 - val_loss: 1.4348\n",
      "Epoch 829/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9548 - loss: 0.3203\n",
      "Epoch 829: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9547 - loss: 0.3206 - val_accuracy: 0.7200 - val_loss: 1.4086\n",
      "Epoch 830/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9669 - loss: 0.3008\n",
      "Epoch 830: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9667 - loss: 0.3008 - val_accuracy: 0.7040 - val_loss: 1.5271\n",
      "Epoch 831/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9594 - loss: 0.3043\n",
      "Epoch 831: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9594 - loss: 0.3046 - val_accuracy: 0.7040 - val_loss: 1.3620\n",
      "Epoch 832/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9659 - loss: 0.2982\n",
      "Epoch 832: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9658 - loss: 0.2988 - val_accuracy: 0.7200 - val_loss: 1.3087\n",
      "Epoch 833/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9472 - loss: 0.3323\n",
      "Epoch 833: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9471 - loss: 0.3326 - val_accuracy: 0.7360 - val_loss: 1.3486\n",
      "Epoch 834/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9491 - loss: 0.3354\n",
      "Epoch 834: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9491 - loss: 0.3352 - val_accuracy: 0.7320 - val_loss: 1.3513\n",
      "Epoch 835/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9556 - loss: 0.3157\n",
      "Epoch 835: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9556 - loss: 0.3159 - val_accuracy: 0.7200 - val_loss: 1.3582\n",
      "Epoch 836/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9578 - loss: 0.3031\n",
      "Epoch 836: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9577 - loss: 0.3033 - val_accuracy: 0.7120 - val_loss: 1.4098\n",
      "Epoch 837/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9578 - loss: 0.3066\n",
      "Epoch 837: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9576 - loss: 0.3069 - val_accuracy: 0.7320 - val_loss: 1.3010\n",
      "Epoch 838/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9507 - loss: 0.3137\n",
      "Epoch 838: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9506 - loss: 0.3138 - val_accuracy: 0.7040 - val_loss: 1.4223\n",
      "Epoch 839/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9597 - loss: 0.3082\n",
      "Epoch 839: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9596 - loss: 0.3087 - val_accuracy: 0.7560 - val_loss: 1.3009\n",
      "Epoch 840/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9575 - loss: 0.3113\n",
      "Epoch 840: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9575 - loss: 0.3110 - val_accuracy: 0.7160 - val_loss: 1.2985\n",
      "Epoch 841/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9557 - loss: 0.3014\n",
      "Epoch 841: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9557 - loss: 0.3016 - val_accuracy: 0.7000 - val_loss: 1.3303\n",
      "Epoch 842/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9597 - loss: 0.2925\n",
      "Epoch 842: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9596 - loss: 0.2931 - val_accuracy: 0.7040 - val_loss: 1.4867\n",
      "Epoch 843/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9685 - loss: 0.2805\n",
      "Epoch 843: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9685 - loss: 0.2808 - val_accuracy: 0.7280 - val_loss: 1.3783\n",
      "Epoch 844/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9521 - loss: 0.3230\n",
      "Epoch 844: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9520 - loss: 0.3229 - val_accuracy: 0.7280 - val_loss: 1.4732\n",
      "Epoch 845/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9675 - loss: 0.2923\n",
      "Epoch 845: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9675 - loss: 0.2925 - val_accuracy: 0.7240 - val_loss: 1.3088\n",
      "Epoch 846/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9664 - loss: 0.2838\n",
      "Epoch 846: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9657 - loss: 0.2854 - val_accuracy: 0.7240 - val_loss: 1.4011\n",
      "Epoch 847/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9610 - loss: 0.2944\n",
      "Epoch 847: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9609 - loss: 0.2947 - val_accuracy: 0.7480 - val_loss: 1.3286\n",
      "Epoch 848/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9583 - loss: 0.3131\n",
      "Epoch 848: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9583 - loss: 0.3131 - val_accuracy: 0.7160 - val_loss: 1.4101\n",
      "Epoch 849/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9562 - loss: 0.2902\n",
      "Epoch 849: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9562 - loss: 0.2905 - val_accuracy: 0.7280 - val_loss: 1.2863\n",
      "Epoch 850/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9529 - loss: 0.3032\n",
      "Epoch 850: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9528 - loss: 0.3037 - val_accuracy: 0.7280 - val_loss: 1.3342\n",
      "Epoch 851/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9563 - loss: 0.3129\n",
      "Epoch 851: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9563 - loss: 0.3130 - val_accuracy: 0.7480 - val_loss: 1.3178\n",
      "Epoch 852/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9565 - loss: 0.3116\n",
      "Epoch 852: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9565 - loss: 0.3115 - val_accuracy: 0.7400 - val_loss: 1.3745\n",
      "Epoch 853/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9581 - loss: 0.3043\n",
      "Epoch 853: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9582 - loss: 0.3041 - val_accuracy: 0.6960 - val_loss: 1.4056\n",
      "Epoch 854/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9549 - loss: 0.3095\n",
      "Epoch 854: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9549 - loss: 0.3095 - val_accuracy: 0.6880 - val_loss: 1.4534\n",
      "Epoch 855/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9689 - loss: 0.2722\n",
      "Epoch 855: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9688 - loss: 0.2725 - val_accuracy: 0.7320 - val_loss: 1.2913\n",
      "Epoch 856/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9555 - loss: 0.3006\n",
      "Epoch 856: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9553 - loss: 0.3014 - val_accuracy: 0.7240 - val_loss: 1.3721\n",
      "Epoch 857/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9476 - loss: 0.3145\n",
      "Epoch 857: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9477 - loss: 0.3145 - val_accuracy: 0.7360 - val_loss: 1.3993\n",
      "Epoch 858/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9575 - loss: 0.3070\n",
      "Epoch 858: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9573 - loss: 0.3075 - val_accuracy: 0.7440 - val_loss: 1.4900\n",
      "Epoch 859/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9433 - loss: 0.3331\n",
      "Epoch 859: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9434 - loss: 0.3330 - val_accuracy: 0.7160 - val_loss: 1.3498\n",
      "Epoch 860/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9499 - loss: 0.3215\n",
      "Epoch 860: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9499 - loss: 0.3215 - val_accuracy: 0.7360 - val_loss: 1.2742\n",
      "Epoch 861/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9631 - loss: 0.3175\n",
      "Epoch 861: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9629 - loss: 0.3177 - val_accuracy: 0.7320 - val_loss: 1.3747\n",
      "Epoch 862/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9455 - loss: 0.3370\n",
      "Epoch 862: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9454 - loss: 0.3369 - val_accuracy: 0.7080 - val_loss: 1.4392\n",
      "Epoch 863/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9538 - loss: 0.3142\n",
      "Epoch 863: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9538 - loss: 0.3143 - val_accuracy: 0.7280 - val_loss: 1.3839\n",
      "Epoch 864/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9595 - loss: 0.2920\n",
      "Epoch 864: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9595 - loss: 0.2924 - val_accuracy: 0.7440 - val_loss: 1.3994\n",
      "Epoch 865/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9570 - loss: 0.3034\n",
      "Epoch 865: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9569 - loss: 0.3035 - val_accuracy: 0.7240 - val_loss: 1.3646\n",
      "Epoch 866/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9515 - loss: 0.3176\n",
      "Epoch 866: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9516 - loss: 0.3172 - val_accuracy: 0.7280 - val_loss: 1.3632\n",
      "Epoch 867/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9540 - loss: 0.2966\n",
      "Epoch 867: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9540 - loss: 0.2969 - val_accuracy: 0.7320 - val_loss: 1.3761\n",
      "Epoch 868/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9546 - loss: 0.3084\n",
      "Epoch 868: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9546 - loss: 0.3083 - val_accuracy: 0.7000 - val_loss: 1.3815\n",
      "Epoch 869/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9495 - loss: 0.3152\n",
      "Epoch 869: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9496 - loss: 0.3152 - val_accuracy: 0.7520 - val_loss: 1.3584\n",
      "Epoch 870/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9512 - loss: 0.3115\n",
      "Epoch 870: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9513 - loss: 0.3114 - val_accuracy: 0.7480 - val_loss: 1.2797\n",
      "Epoch 871/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9556 - loss: 0.3196\n",
      "Epoch 871: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9556 - loss: 0.3195 - val_accuracy: 0.7400 - val_loss: 1.3105\n",
      "Epoch 872/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9498 - loss: 0.3180\n",
      "Epoch 872: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9499 - loss: 0.3179 - val_accuracy: 0.7200 - val_loss: 1.4357\n",
      "Epoch 873/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9502 - loss: 0.3413\n",
      "Epoch 873: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9502 - loss: 0.3406 - val_accuracy: 0.7240 - val_loss: 1.3977\n",
      "Epoch 874/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9561 - loss: 0.3113\n",
      "Epoch 874: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9560 - loss: 0.3117 - val_accuracy: 0.7400 - val_loss: 1.4355\n",
      "Epoch 875/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9559 - loss: 0.3050\n",
      "Epoch 875: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9559 - loss: 0.3050 - val_accuracy: 0.7120 - val_loss: 1.4610\n",
      "Epoch 876/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9517 - loss: 0.3233\n",
      "Epoch 876: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9518 - loss: 0.3230 - val_accuracy: 0.7040 - val_loss: 1.4644\n",
      "Epoch 877/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9530 - loss: 0.3428\n",
      "Epoch 877: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9527 - loss: 0.3431 - val_accuracy: 0.7520 - val_loss: 1.3549\n",
      "Epoch 878/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9735 - loss: 0.2757\n",
      "Epoch 878: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9730 - loss: 0.2767 - val_accuracy: 0.7160 - val_loss: 1.3872\n",
      "Epoch 879/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9591 - loss: 0.3180\n",
      "Epoch 879: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9589 - loss: 0.3183 - val_accuracy: 0.7240 - val_loss: 1.3353\n",
      "Epoch 880/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9543 - loss: 0.3187\n",
      "Epoch 880: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9543 - loss: 0.3192 - val_accuracy: 0.7320 - val_loss: 1.3738\n",
      "Epoch 881/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9542 - loss: 0.3172\n",
      "Epoch 881: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9543 - loss: 0.3172 - val_accuracy: 0.7280 - val_loss: 1.4060\n",
      "Epoch 882/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9566 - loss: 0.3153\n",
      "Epoch 882: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9566 - loss: 0.3153 - val_accuracy: 0.7320 - val_loss: 1.3471\n",
      "Epoch 883/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9507 - loss: 0.3342\n",
      "Epoch 883: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9508 - loss: 0.3339 - val_accuracy: 0.7040 - val_loss: 1.3958\n",
      "Epoch 884/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9553 - loss: 0.3059\n",
      "Epoch 884: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9552 - loss: 0.3065 - val_accuracy: 0.7440 - val_loss: 1.3201\n",
      "Epoch 885/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9523 - loss: 0.3314\n",
      "Epoch 885: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9524 - loss: 0.3309 - val_accuracy: 0.7200 - val_loss: 1.3693\n",
      "Epoch 886/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9511 - loss: 0.3046\n",
      "Epoch 886: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9513 - loss: 0.3048 - val_accuracy: 0.7200 - val_loss: 1.3778\n",
      "Epoch 887/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9643 - loss: 0.3009\n",
      "Epoch 887: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9639 - loss: 0.3016 - val_accuracy: 0.7200 - val_loss: 1.3229\n",
      "Epoch 888/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9549 - loss: 0.3057\n",
      "Epoch 888: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9548 - loss: 0.3061 - val_accuracy: 0.7120 - val_loss: 1.3706\n",
      "Epoch 889/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9485 - loss: 0.3113\n",
      "Epoch 889: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9485 - loss: 0.3114 - val_accuracy: 0.7120 - val_loss: 1.3508\n",
      "Epoch 890/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9554 - loss: 0.3160\n",
      "Epoch 890: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9553 - loss: 0.3162 - val_accuracy: 0.7480 - val_loss: 1.2480\n",
      "Epoch 891/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9614 - loss: 0.2879\n",
      "Epoch 891: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9614 - loss: 0.2882 - val_accuracy: 0.7400 - val_loss: 1.2552\n",
      "Epoch 892/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9685 - loss: 0.2732\n",
      "Epoch 892: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9685 - loss: 0.2730 - val_accuracy: 0.7480 - val_loss: 1.2073\n",
      "Epoch 893/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9625 - loss: 0.2847\n",
      "Epoch 893: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.9625 - loss: 0.2848 - val_accuracy: 0.7400 - val_loss: 1.2631\n",
      "Epoch 894/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9572 - loss: 0.2943\n",
      "Epoch 894: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.9571 - loss: 0.2944 - val_accuracy: 0.7120 - val_loss: 1.3184\n",
      "Epoch 895/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9552 - loss: 0.3080\n",
      "Epoch 895: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9551 - loss: 0.3085 - val_accuracy: 0.7080 - val_loss: 1.4214\n",
      "Epoch 896/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9658 - loss: 0.2857\n",
      "Epoch 896: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9658 - loss: 0.2857 - val_accuracy: 0.7360 - val_loss: 1.3577\n",
      "Epoch 897/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9545 - loss: 0.2986\n",
      "Epoch 897: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9545 - loss: 0.2986 - val_accuracy: 0.7240 - val_loss: 1.3162\n",
      "Epoch 898/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9599 - loss: 0.3236\n",
      "Epoch 898: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9598 - loss: 0.3226 - val_accuracy: 0.7360 - val_loss: 1.3302\n",
      "Epoch 899/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9534 - loss: 0.2854\n",
      "Epoch 899: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9531 - loss: 0.2864 - val_accuracy: 0.7200 - val_loss: 1.4097\n",
      "Epoch 900/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9611 - loss: 0.3039\n",
      "Epoch 900: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9610 - loss: 0.3041 - val_accuracy: 0.7200 - val_loss: 1.3536\n",
      "Epoch 901/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9537 - loss: 0.3084\n",
      "Epoch 901: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9537 - loss: 0.3088 - val_accuracy: 0.7400 - val_loss: 1.3100\n",
      "Epoch 902/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9629 - loss: 0.2912\n",
      "Epoch 902: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9628 - loss: 0.2912 - val_accuracy: 0.7360 - val_loss: 1.3858\n",
      "Epoch 903/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9433 - loss: 0.3185\n",
      "Epoch 903: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9434 - loss: 0.3183 - val_accuracy: 0.7480 - val_loss: 1.3878\n",
      "Epoch 904/1000\n",
      "\u001b[1m68/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9524 - loss: 0.3230\n",
      "Epoch 904: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9526 - loss: 0.3231 - val_accuracy: 0.7240 - val_loss: 1.3751\n",
      "Epoch 905/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9558 - loss: 0.3031\n",
      "Epoch 905: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9558 - loss: 0.3031 - val_accuracy: 0.7320 - val_loss: 1.3110\n",
      "Epoch 906/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9546 - loss: 0.2885\n",
      "Epoch 906: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9545 - loss: 0.2887 - val_accuracy: 0.7440 - val_loss: 1.4514\n",
      "Epoch 907/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9525 - loss: 0.3327\n",
      "Epoch 907: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9525 - loss: 0.3325 - val_accuracy: 0.7200 - val_loss: 1.3718\n",
      "Epoch 908/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9591 - loss: 0.2997\n",
      "Epoch 908: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9590 - loss: 0.2999 - val_accuracy: 0.7320 - val_loss: 1.3862\n",
      "Epoch 909/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9417 - loss: 0.3591\n",
      "Epoch 909: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9418 - loss: 0.3587 - val_accuracy: 0.7240 - val_loss: 1.3906\n",
      "Epoch 910/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9690 - loss: 0.2916\n",
      "Epoch 910: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9689 - loss: 0.2919 - val_accuracy: 0.7240 - val_loss: 1.3535\n",
      "Epoch 911/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9632 - loss: 0.2830\n",
      "Epoch 911: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9631 - loss: 0.2833 - val_accuracy: 0.7240 - val_loss: 1.3581\n",
      "Epoch 912/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9578 - loss: 0.3117\n",
      "Epoch 912: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9578 - loss: 0.3117 - val_accuracy: 0.7360 - val_loss: 1.2831\n",
      "Epoch 913/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9629 - loss: 0.2984\n",
      "Epoch 913: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9628 - loss: 0.2985 - val_accuracy: 0.7320 - val_loss: 1.3418\n",
      "Epoch 914/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9518 - loss: 0.3200\n",
      "Epoch 914: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9518 - loss: 0.3201 - val_accuracy: 0.7440 - val_loss: 1.3218\n",
      "Epoch 915/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9613 - loss: 0.2812\n",
      "Epoch 915: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9612 - loss: 0.2816 - val_accuracy: 0.7200 - val_loss: 1.3072\n",
      "Epoch 916/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9588 - loss: 0.2938\n",
      "Epoch 916: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9586 - loss: 0.2946 - val_accuracy: 0.7440 - val_loss: 1.2674\n",
      "Epoch 917/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9536 - loss: 0.2938\n",
      "Epoch 917: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9535 - loss: 0.2942 - val_accuracy: 0.7160 - val_loss: 1.3689\n",
      "Epoch 918/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9599 - loss: 0.2927\n",
      "Epoch 918: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9599 - loss: 0.2928 - val_accuracy: 0.7440 - val_loss: 1.3368\n",
      "Epoch 919/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9662 - loss: 0.2858\n",
      "Epoch 919: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9661 - loss: 0.2858 - val_accuracy: 0.7080 - val_loss: 1.3584\n",
      "Epoch 920/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9617 - loss: 0.2860\n",
      "Epoch 920: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.9618 - loss: 0.2860 - val_accuracy: 0.7320 - val_loss: 1.3275\n",
      "Epoch 921/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9490 - loss: 0.3153\n",
      "Epoch 921: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9491 - loss: 0.3149 - val_accuracy: 0.7320 - val_loss: 1.3282\n",
      "Epoch 922/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9568 - loss: 0.3059\n",
      "Epoch 922: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9567 - loss: 0.3059 - val_accuracy: 0.7520 - val_loss: 1.2716\n",
      "Epoch 923/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9631 - loss: 0.2807\n",
      "Epoch 923: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9631 - loss: 0.2808 - val_accuracy: 0.7320 - val_loss: 1.3280\n",
      "Epoch 924/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9525 - loss: 0.2938\n",
      "Epoch 924: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9524 - loss: 0.2947 - val_accuracy: 0.7280 - val_loss: 1.3280\n",
      "Epoch 925/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9565 - loss: 0.2988\n",
      "Epoch 925: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9563 - loss: 0.2997 - val_accuracy: 0.7400 - val_loss: 1.3178\n",
      "Epoch 926/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9540 - loss: 0.3107\n",
      "Epoch 926: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9538 - loss: 0.3110 - val_accuracy: 0.7240 - val_loss: 1.3432\n",
      "Epoch 927/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9501 - loss: 0.3139\n",
      "Epoch 927: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9500 - loss: 0.3142 - val_accuracy: 0.7160 - val_loss: 1.3720\n",
      "Epoch 928/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9534 - loss: 0.3222\n",
      "Epoch 928: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9535 - loss: 0.3221 - val_accuracy: 0.7520 - val_loss: 1.2970\n",
      "Epoch 929/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9585 - loss: 0.3201\n",
      "Epoch 929: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9586 - loss: 0.3200 - val_accuracy: 0.7440 - val_loss: 1.3071\n",
      "Epoch 930/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9485 - loss: 0.3231\n",
      "Epoch 930: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9485 - loss: 0.3229 - val_accuracy: 0.7320 - val_loss: 1.3971\n",
      "Epoch 931/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9601 - loss: 0.2897\n",
      "Epoch 931: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9601 - loss: 0.2897 - val_accuracy: 0.7440 - val_loss: 1.4065\n",
      "Epoch 932/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9578 - loss: 0.2948\n",
      "Epoch 932: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9577 - loss: 0.2950 - val_accuracy: 0.7440 - val_loss: 1.2919\n",
      "Epoch 933/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9501 - loss: 0.3137\n",
      "Epoch 933: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9502 - loss: 0.3135 - val_accuracy: 0.7320 - val_loss: 1.3110\n",
      "Epoch 934/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9537 - loss: 0.3149\n",
      "Epoch 934: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9537 - loss: 0.3150 - val_accuracy: 0.7280 - val_loss: 1.3558\n",
      "Epoch 935/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9647 - loss: 0.2902\n",
      "Epoch 935: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9646 - loss: 0.2903 - val_accuracy: 0.7400 - val_loss: 1.3674\n",
      "Epoch 936/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9472 - loss: 0.3295\n",
      "Epoch 936: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9472 - loss: 0.3297 - val_accuracy: 0.7360 - val_loss: 1.4335\n",
      "Epoch 937/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9607 - loss: 0.3095\n",
      "Epoch 937: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9605 - loss: 0.3097 - val_accuracy: 0.7160 - val_loss: 1.3402\n",
      "Epoch 938/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9549 - loss: 0.3270\n",
      "Epoch 938: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9548 - loss: 0.3268 - val_accuracy: 0.7560 - val_loss: 1.3078\n",
      "Epoch 939/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9569 - loss: 0.3125\n",
      "Epoch 939: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9568 - loss: 0.3131 - val_accuracy: 0.7400 - val_loss: 1.2561\n",
      "Epoch 940/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9600 - loss: 0.3098\n",
      "Epoch 940: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9599 - loss: 0.3101 - val_accuracy: 0.7440 - val_loss: 1.3566\n",
      "Epoch 941/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9634 - loss: 0.2894\n",
      "Epoch 941: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9631 - loss: 0.2900 - val_accuracy: 0.7480 - val_loss: 1.3177\n",
      "Epoch 942/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9559 - loss: 0.3003\n",
      "Epoch 942: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9559 - loss: 0.3004 - val_accuracy: 0.7200 - val_loss: 1.3570\n",
      "Epoch 943/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9641 - loss: 0.2949\n",
      "Epoch 943: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9639 - loss: 0.2953 - val_accuracy: 0.7200 - val_loss: 1.3734\n",
      "Epoch 944/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9594 - loss: 0.2849\n",
      "Epoch 944: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9594 - loss: 0.2853 - val_accuracy: 0.7240 - val_loss: 1.3511\n",
      "Epoch 945/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9592 - loss: 0.3012\n",
      "Epoch 945: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9591 - loss: 0.3013 - val_accuracy: 0.7120 - val_loss: 1.3368\n",
      "Epoch 946/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9498 - loss: 0.3207\n",
      "Epoch 946: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9498 - loss: 0.3207 - val_accuracy: 0.7320 - val_loss: 1.3305\n",
      "Epoch 947/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9559 - loss: 0.2969\n",
      "Epoch 947: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9559 - loss: 0.2969 - val_accuracy: 0.7240 - val_loss: 1.3685\n",
      "Epoch 948/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9622 - loss: 0.2784\n",
      "Epoch 948: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9621 - loss: 0.2785 - val_accuracy: 0.7360 - val_loss: 1.3840\n",
      "Epoch 949/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9472 - loss: 0.3099\n",
      "Epoch 949: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9473 - loss: 0.3099 - val_accuracy: 0.7360 - val_loss: 1.4033\n",
      "Epoch 950/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9594 - loss: 0.2899\n",
      "Epoch 950: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9593 - loss: 0.2900 - val_accuracy: 0.6960 - val_loss: 1.4417\n",
      "Epoch 951/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9590 - loss: 0.2845\n",
      "Epoch 951: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9590 - loss: 0.2845 - val_accuracy: 0.7320 - val_loss: 1.3263\n",
      "Epoch 952/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9682 - loss: 0.2685\n",
      "Epoch 952: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9680 - loss: 0.2689 - val_accuracy: 0.7280 - val_loss: 1.3350\n",
      "Epoch 953/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9562 - loss: 0.2934\n",
      "Epoch 953: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9562 - loss: 0.2934 - val_accuracy: 0.7360 - val_loss: 1.3088\n",
      "Epoch 954/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9769 - loss: 0.2559\n",
      "Epoch 954: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9768 - loss: 0.2560 - val_accuracy: 0.7280 - val_loss: 1.3356\n",
      "Epoch 955/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9513 - loss: 0.2866\n",
      "Epoch 955: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9515 - loss: 0.2865 - val_accuracy: 0.7600 - val_loss: 1.3816\n",
      "Epoch 956/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9485 - loss: 0.3023\n",
      "Epoch 956: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9483 - loss: 0.3029 - val_accuracy: 0.7320 - val_loss: 1.3540\n",
      "Epoch 957/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9586 - loss: 0.2876\n",
      "Epoch 957: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9585 - loss: 0.2878 - val_accuracy: 0.7400 - val_loss: 1.2768\n",
      "Epoch 958/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9502 - loss: 0.3044\n",
      "Epoch 958: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9502 - loss: 0.3046 - val_accuracy: 0.7520 - val_loss: 1.3221\n",
      "Epoch 959/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9521 - loss: 0.3148\n",
      "Epoch 959: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9522 - loss: 0.3145 - val_accuracy: 0.7280 - val_loss: 1.3409\n",
      "Epoch 960/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9637 - loss: 0.2774\n",
      "Epoch 960: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9636 - loss: 0.2775 - val_accuracy: 0.7360 - val_loss: 1.2867\n",
      "Epoch 961/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9514 - loss: 0.3161\n",
      "Epoch 961: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9514 - loss: 0.3161 - val_accuracy: 0.7080 - val_loss: 1.3749\n",
      "Epoch 962/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9504 - loss: 0.3144\n",
      "Epoch 962: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9505 - loss: 0.3142 - val_accuracy: 0.7120 - val_loss: 1.3582\n",
      "Epoch 963/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9668 - loss: 0.2745\n",
      "Epoch 963: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9667 - loss: 0.2746 - val_accuracy: 0.7400 - val_loss: 1.2543\n",
      "Epoch 964/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9612 - loss: 0.2803\n",
      "Epoch 964: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9611 - loss: 0.2803 - val_accuracy: 0.7040 - val_loss: 1.3726\n",
      "Epoch 965/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9641 - loss: 0.2773\n",
      "Epoch 965: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9641 - loss: 0.2772 - val_accuracy: 0.7440 - val_loss: 1.3271\n",
      "Epoch 966/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9708 - loss: 0.2570\n",
      "Epoch 966: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9704 - loss: 0.2575 - val_accuracy: 0.7320 - val_loss: 1.3263\n",
      "Epoch 967/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9545 - loss: 0.2894\n",
      "Epoch 967: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9544 - loss: 0.2898 - val_accuracy: 0.7000 - val_loss: 1.4621\n",
      "Epoch 968/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9710 - loss: 0.2640\n",
      "Epoch 968: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.9707 - loss: 0.2648 - val_accuracy: 0.7200 - val_loss: 1.4507\n",
      "Epoch 969/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9514 - loss: 0.3102\n",
      "Epoch 969: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9514 - loss: 0.3105 - val_accuracy: 0.7000 - val_loss: 1.4047\n",
      "Epoch 970/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9549 - loss: 0.3027\n",
      "Epoch 970: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9548 - loss: 0.3030 - val_accuracy: 0.7320 - val_loss: 1.3547\n",
      "Epoch 971/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9501 - loss: 0.3379\n",
      "Epoch 971: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9503 - loss: 0.3373 - val_accuracy: 0.7320 - val_loss: 1.4454\n",
      "Epoch 972/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9634 - loss: 0.2814\n",
      "Epoch 972: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9633 - loss: 0.2816 - val_accuracy: 0.7400 - val_loss: 1.3307\n",
      "Epoch 973/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9580 - loss: 0.2999\n",
      "Epoch 973: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9580 - loss: 0.2999 - val_accuracy: 0.7240 - val_loss: 1.4182\n",
      "Epoch 974/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9578 - loss: 0.2863\n",
      "Epoch 974: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9576 - loss: 0.2870 - val_accuracy: 0.7400 - val_loss: 1.3432\n",
      "Epoch 975/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9539 - loss: 0.2962\n",
      "Epoch 975: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.9541 - loss: 0.2961 - val_accuracy: 0.7280 - val_loss: 1.3122\n",
      "Epoch 976/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9662 - loss: 0.2685\n",
      "Epoch 976: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9660 - loss: 0.2689 - val_accuracy: 0.7160 - val_loss: 1.3721\n",
      "Epoch 977/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9579 - loss: 0.3061\n",
      "Epoch 977: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9580 - loss: 0.3056 - val_accuracy: 0.7280 - val_loss: 1.2997\n",
      "Epoch 978/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9642 - loss: 0.2710\n",
      "Epoch 978: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9640 - loss: 0.2715 - val_accuracy: 0.7160 - val_loss: 1.4354\n",
      "Epoch 979/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9448 - loss: 0.3182\n",
      "Epoch 979: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9450 - loss: 0.3181 - val_accuracy: 0.7160 - val_loss: 1.3152\n",
      "Epoch 980/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9555 - loss: 0.2973\n",
      "Epoch 980: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9556 - loss: 0.2976 - val_accuracy: 0.7320 - val_loss: 1.3845\n",
      "Epoch 981/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9599 - loss: 0.2900\n",
      "Epoch 981: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9598 - loss: 0.2901 - val_accuracy: 0.7480 - val_loss: 1.2737\n",
      "Epoch 982/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9572 - loss: 0.2953\n",
      "Epoch 982: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.9572 - loss: 0.2953 - val_accuracy: 0.7120 - val_loss: 1.2797\n",
      "Epoch 983/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9601 - loss: 0.3026\n",
      "Epoch 983: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9600 - loss: 0.3029 - val_accuracy: 0.7280 - val_loss: 1.3029\n",
      "Epoch 984/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9455 - loss: 0.3187\n",
      "Epoch 984: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9453 - loss: 0.3189 - val_accuracy: 0.7240 - val_loss: 1.2489\n",
      "Epoch 985/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9724 - loss: 0.2743\n",
      "Epoch 985: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9723 - loss: 0.2745 - val_accuracy: 0.7240 - val_loss: 1.2960\n",
      "Epoch 986/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9629 - loss: 0.2862\n",
      "Epoch 986: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9628 - loss: 0.2864 - val_accuracy: 0.7080 - val_loss: 1.2939\n",
      "Epoch 987/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9500 - loss: 0.3233\n",
      "Epoch 987: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9502 - loss: 0.3228 - val_accuracy: 0.7000 - val_loss: 1.3547\n",
      "Epoch 988/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9631 - loss: 0.2889\n",
      "Epoch 988: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9628 - loss: 0.2896 - val_accuracy: 0.7120 - val_loss: 1.3630\n",
      "Epoch 989/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9626 - loss: 0.2902\n",
      "Epoch 989: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9624 - loss: 0.2903 - val_accuracy: 0.7160 - val_loss: 1.3865\n",
      "Epoch 990/1000\n",
      "\u001b[1m70/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9573 - loss: 0.2967\n",
      "Epoch 990: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9574 - loss: 0.2965 - val_accuracy: 0.7160 - val_loss: 1.3174\n",
      "Epoch 991/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9647 - loss: 0.2835\n",
      "Epoch 991: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9646 - loss: 0.2836 - val_accuracy: 0.7320 - val_loss: 1.2869\n",
      "Epoch 992/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9494 - loss: 0.3086\n",
      "Epoch 992: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9494 - loss: 0.3087 - val_accuracy: 0.7520 - val_loss: 1.2355\n",
      "Epoch 993/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9599 - loss: 0.2954\n",
      "Epoch 993: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9598 - loss: 0.2959 - val_accuracy: 0.7520 - val_loss: 1.1891\n",
      "Epoch 994/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9577 - loss: 0.2820\n",
      "Epoch 994: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9574 - loss: 0.2830 - val_accuracy: 0.7600 - val_loss: 1.2358\n",
      "Epoch 995/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9520 - loss: 0.3175\n",
      "Epoch 995: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9521 - loss: 0.3177 - val_accuracy: 0.7320 - val_loss: 1.2515\n",
      "Epoch 996/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9591 - loss: 0.3002\n",
      "Epoch 996: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9590 - loss: 0.3003 - val_accuracy: 0.7400 - val_loss: 1.2625\n",
      "Epoch 997/1000\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9533 - loss: 0.3001\n",
      "Epoch 997: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9533 - loss: 0.3001 - val_accuracy: 0.7280 - val_loss: 1.3446\n",
      "Epoch 998/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9540 - loss: 0.2921\n",
      "Epoch 998: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9540 - loss: 0.2927 - val_accuracy: 0.7280 - val_loss: 1.2983\n",
      "Epoch 999/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9572 - loss: 0.3024\n",
      "Epoch 999: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.9572 - loss: 0.3028 - val_accuracy: 0.7520 - val_loss: 1.2943\n",
      "Epoch 1000/1000\n",
      "\u001b[1m69/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9521 - loss: 0.3163\n",
      "Epoch 1000: val_accuracy did not improve from 0.76400\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9520 - loss: 0.3167 - val_accuracy: 0.7360 - val_loss: 1.2994\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))  \n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))  \n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))  \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))  \n",
    "\n",
    "model.add(Dense(len(uniq_fineClass), activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Use Adam optimizer with a lower learning rate\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)\n",
    "\n",
    "metricInfo = model.fit(train_images, train_labels, epochs=1000, validation_split=0.1, callbacks=[early_stopping]) #callbacks=[early_stopping]\n",
    "\n",
    "loss = metricInfo.history['loss']\n",
    "val_loss = metricInfo.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# Define a callback to save the best model during training\n",
    "checkpoint_filepath = 'C:\\\\Users\\\\Zamskie\\\\Documents\\\\jason 3rd year\\\\2ND SEM\\\\cpe emerging\\\\bestModel\\\\best_model2.keras'\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with the ModelCheckpoint callback\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=1000,  # Adjust the number of epochs\n",
    "    validation_split=0.1,\n",
    "    callbacks=[model_checkpoint]\n",
    ")\n",
    "\n",
    "# Load the best model\n",
    "#best_model = tf.keras.models.load_model(checkpoint_filepath)\n",
    "\n",
    "# Evaluate the model or use it for predictions\n",
    "#test_loss, test_accuracy = best_model.evaluate(test_images, test_labels)\n",
    "#print('Test Accuracy of the Best Model:', test_accuracy)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(epochs, loss, 'g-', label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, 'b-', label='Validation loss')\n",
    "plt.title('Training vs Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 32, 32, 3)\n",
      "Class in the testing image: [0 1 2 3 4]\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7549 - loss: 1.2457\n",
      "Total number of testing image: 500\n",
      "Test accuracy: 0.75\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "\n",
      "Displaying prediction of the first test input image: [1.1011270e-07 4.6617166e-05 9.9909389e-01 8.5915934e-04 2.7132020e-07]\n",
      "Predicted class: 2--cans\n",
      "True class: 2 -- cans\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     bottles       0.84      0.84      0.84       100\n",
      "        bowl       0.69      0.59      0.63       100\n",
      "        cans       0.70      0.81      0.75       100\n",
      "        cups       0.84      0.76      0.80       100\n",
      "      plates       0.69      0.75      0.72       100\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.75      0.75      0.75       500\n",
      "weighted avg       0.75      0.75      0.75       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "str_class = ['bottles', 'bowl', 'cans', 'cups', 'plates']\n",
    "\n",
    "print(test_images.shape)\n",
    "print(\"Class in the testing image: {}\".format(np.unique(test_labels)))\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Total number of testing image: {}'.format(len(test_images)))\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Another way to test using \"prediction\" method\n",
    "classification = model.predict(test_images)\n",
    "print('\\nDisplaying prediction of the first test input image: {}'.format(classification[0]))\n",
    "\n",
    "# get the index of the maximum probability in the classification[0] result\n",
    "max_prob_idx = np.argmax(classification[0])\n",
    "print('Predicted class: {}--{}'.format(max_prob_idx, str_class[max_prob_idx]))\n",
    "idx = test_labels[0]\n",
    "print('True class: {} -- {}'.format(idx[0], str_class[idx[0]]))\n",
    "\n",
    "# Evaluate the model on a per-class basis\n",
    "y_true = test_labels\n",
    "y_pred = np.argmax(classification, axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=str_class)\n",
    "print('\\nClassification Report:\\n', report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
